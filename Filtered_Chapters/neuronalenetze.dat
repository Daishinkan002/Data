[introduction, motivation, history] teach computer either write fixed program enable computer learn living beings programmer writing program developing skills executed learn without previous knowledge external impressions thus solve problems better computer today qualities needed achieve behavior devices like computers cognition adapted biology history development decline resurgence wide approach solve problems 
[introduction, motivation, history, neural, networks] problem categories cannot formulated algorithm problems depend many subtle factors example purchase price real estate brain approximately calculate without algorithm computer cannot therefore question asked learn explore problems exactly learn capability computers obviously humans brain learn computers processing units memory allow computer perform complex numerical calculations short time adaptive compare computer brain note theoretically computer powerful brain comprises course comparison obvious reasons controversially discussed biologists computer scientists since response time quantity tell anything quality performance processing units well neurons transistors cannot compared directly nevertheless comparison serves purpose indicates advantage parallelism means processing time brain computer processing units type processing units neurons transistors type calculation massively parallel usually serial data storage associative address based switching time possible switching operations actual switching operations table flawed comparison brain computer glance inspired transistors switching time seconds brain contains neurons switching time seconds largest part brain working continuously largest part com puter passive data storage thus brain parallel therefore performing close theoretical maximum computer orders magnitude away table additionally computer static brain biological neural network reorganize lifespan therefore able learn compensate errors forth within text want outline use said characteristics brain computer system study artificial neural networks motivated similarity successfully working biological systems comparison overall system consist simple numerous nerve cells work massively parallel probably one significant aspects capability learn need explicitly program neural network instance learn training samples means encouragement carrot stick speak reinforcement learning one result learning procedure capability neural networks gen eralize associate data successful training neural network find reasonable solutions similar problems class explicitly trained turn results high degree fault tolerance noisy input data fault tolerance closely related biological neural networks character istic distinct previously mentioned human neurons continuously reorganize reorganized external influences neurons destroyed drunken stupor types food envi ronmental influences also destroy brain cells nevertheless cognitive abilities significantly affected thus brain tolerant internal errors also external errors often read really dreadful scrawl although individual letters nearly impossible read modern technology however automatically fault tolerant never heard someone forgot install hard disk controller computer therefore graphics card automatically took tasks removed conductors developed communication system whole affected missing component completely destroyed disadvantage distributed fault tolerant storage certainly fact cannot realize first sight neural neutwork knows performs faults lie usually easier perform analyses conventional algorithms often transfer knowledge neural network means learning procedure cause several errors always easy manage fault tolerance data hand already sophisticated state art technology let compare record scratch record audio information spot completely lost hear pop music goes audio data distributedly stored scratch causes blurry sound vicinity data stream remains largely unaffected listener notice anything let summarize main characteristics try adapt biology self organization learning capability generalization capability fault tolerance types neural networks particularly develop kinds abilities used problem classes discussed course work introductory chapter want clarify following neural network exist different paradigms neural networks trained used goal introduce paradigms supplement remarks practical application already mentioned brain works massively parallel contrast functioning computer every component active time want state argument massive parallel processing step rule cited 
[introduction, motivation, history, neural, networks, step, rule] experiments showed human recognize picture familiar object person seconds corresponds neuron switching time seconds discrete time steps parallel processing computer following von neumann architecture however practically noth ing time steps sequential processing assembler steps cycle steps want look simple application example neural network 
[introduction, motivation, history, neural, networks, simple, application, examples] let assume small robot shown fig robot eight distance sensors extracts input data three sensors placed front right three front left two back sensor provides real numeric value time means always receiving input despite two motors needed later robot simple example capable much shall drive stop might collide obstacle thus output binary everything okay drive stop output called halt signal therefore need mapping applies input signals robot activity classical way two ways realizing mapping one hand classical way sit think finally result circuit small computer program realizes mapping easily possible since example simple refer technical reference sensors study characteristic curve order learn values different obstacle distances embed values aforementioned set rules procedures applied figure small robot eight sensors two motors arrow indicates driving direction classic artificial intelligence know exact rules mapping algorithm always well advised follow scheme way learning hand interesting successful many mappings problems hard comprehend straightaway way learning show different possible situations robot fig robot shall learn course robot life example robot shall simply learn stop first treat neural network kind black box fig means know structure regard behavior practice situations form simply measured sensor values placing robot front obstacle see illustration show robot specify whether drive stop called training samples thus training sample consists exemplary input corresponding desired output question transfer knowledge information neural network figure robot positioned landscape provides sensor values different situa tions add desired output values receive learning samples directions sensors oriented exemplarily applied two robots figure initially regard robot control black box whose inner life unknown black box receives eight real sensor values maps values binary output value samples taught neural network using simple learning procedure learning procedure simple algorithm mathematical formula done everything right chosen good samples neural network generalize samples find universal rule stop example optionally expanded purpose direction control would possible control motors robot separately sensor layout case looking mapping gradually controls two motors means sensor inputs thus cannot example stop robot also lets avoid obstacles difficult analytically derive rules facto neural network would appropriate goal learn samples heart realize principle behind ideally robot apply neural network situation able avoid obstacles particular robot query network continuously repeatedly driving order continously avoid obstacles result constant cycle robot queries network consequence drive one direction changes sensors values robot queries network changes position sensor values changed obvious system also adapted dynamic changing environments moving obstacles example 
[introduction, motivation, history, brief, history, neural, networks] field neural networks like field science long history development many ups downs see soon continue style work represent history text form compact form timeline citations bibliographical references added mainly topics discussed text citations keywords explained later mentioned corresponding chapters history neural networks begins early thus nearly simultaneously history programmable electronic computers youth field robot called khepera less similar characteristics round shaped approx diameter two motors wheels various sensors information recommend refer internet figure institutions field neural networks left right john von neu mann donald hebb marvin minsky bernard widrow seymour papert teuvo kohonen john hopfield order appearance far possible research field computer science easily recognized due fact many cited persons still 
[introduction, motivation, history, brief, history, neural, networks, beginning] soon warren mcculloch walter pitts introduced models neurological networks recreated threshold switches based neurons showed even simple networks kind able calculate nearly logic arithmetic function furthermore first computer precursors elec tronic brains developed among others supported konrad zuse tired calculating ballistic trajectories hand walter pitts warren mcculloch indicated practical field applica tion mentioned work namely recognition spacial patterns neural networks donald hebb formulated classical hebbian rule repre sents generalized form basis nearly neural learning proce dures rule implies connection two neurons strengthened neurons active time change strength pro portional product two activities hebb could postulate rule due absence neurological research able verify neuropsychologist karl lashley defended thesis brain informa tion storage realized distributed system thesis based experi ments rats extent location destroyed nerve tissue influences rats performance find way labyrinth 
[introduction, motivation, history, brief, history, neural, networks, golden, age] dissertation marvin minsky developed neurocomputer snark already capable adjust weights automatically never practically implemented since capable busily calculate nobody really knows calculates well known scientists ambitious students met dartmouth sum mer research project discussed put crudely simulate brain differences top bottom research developed early supporters artificial intelligence wanted simulate capabilities means software supporters neural networks wanted achieve system behavior imitating smallest parts system neurons mit frank rosenblatt charles wightman coworkers developed first successful neurocomputer mark perceptron capable recognize simple numerics means pixel image sensor electromechanically worked motor driven potentiometers potentiometer representing one variable weight frank rosenblatt described different versions perceptron formulated verified perceptron convergence theorem described neuron layers mim icking retina threshold switches learning rule adjusting connecting weights bernard widrow marcian hoff introduced adaline adaptive linear neuron fast precise adaptive learning system first widely commercially used neural network could found nearly every analog telephone real time adaptive echo filtering trained menas widrow hoff rule delta rule time hoff later founder intel corporation phd student widrow known inventor modern microprocessors one advantage delta rule original perceptron learning algorithm adaptivity difference actual output correct solution large connecting weights also changed larger steps smaller steps closer target disadvantage missapplication led infinitesimal small steps close target following stagnation fear scientific unpopularity neural networks adaline renamed adaptive linear element undone later learn soon weights karl steinbuch introduced technical realizations associative memory seen predecessors today neural associative memories additionally described concepts neural techniques analyzed possibilities limits book learning machines nils nilsson gave overview progress works period neural network research assumed basic principles self learning therefore generally speaking intelligent systems already discovered today assumption seems exorbitant overestimation time provided high popularity sufficient research funds marvin minsky seymour papert published precise mathematical analysis perceptron show perceptron model capable representing many important problems keywords xor problem linear separability put end overestimation popularity research funds implication powerful models would show exactly problems forecast entire field would research dead end resulted nearly complete decline research funds next years matter incorrect forecasts today point view 
[introduction, motivation, history, brief, history, neural, networks, long, silence, slow, reconstruction] research funds previously mentioned extremely short everywhere search went neither conferences events therefore publications isolation individual researchers provided many dependently developed neural network paradigms researched discourse among spite poor appreciation field received basic theories still continuing renaissance laid time teuvo kohonen introduced model linear associator model associative memory year model presented independently neurophysiologist point view james derson christoph von der malsburg used neuron model non linear biologically motivated dissertation harvard paul werbos developed learning procedure called backpropagation error one decade later procedure reached today importance thereafter stephen grossberg presented many papers instance numerous neural models analyzed mathematically furthermore dedicated problem keeping neural network capable learning without destroying already learned associations cooperation gail carpenter led models adaptive resonance theory art teuvo kohonen described self organizing feature maps som also known kohonen maps looking mechanisms involving self organization brain knew information creation stored genome however enough memory structure like brain consequence brain organize create part john hopfield also invented called hopfield networks inspired laws magnetism physics widely used tech nical applications field neural networks slowly regained importance fukushima miyake ito introduced neural model neocogni tron could recognize handwritten characters extension cognitron network already developed 
[introduction, motivation, history, brief, history, neural, networks, renaissance] influence john hopfield personally convinced many searchers importance field wide publication backpropagation rumelhart hinton williams field neural networks slowly showed signs upswing john hopfield published article describing way finding acceptable solutions travelling salesman problem using hopfield nets backpropagation error learning procedure generalization delta rule separately developed widely published parallel distributed processing group non linearly separable problems could solved multilayer perceptrons marvin minsky negative evaluations dis proven single blow time certain kind fatigue spread field artificial intelligence caused series failures unfulfilled hopes time development field research almost explosive longer itemized results seen following 
[introduction, motivation, history, exercises] exercise give one example following topics book neural networks neuroinformatics collaborative group university working neural networks software tool realizing neural networks simulator company using neural networks product service realized means neural networks exercise show least four applications technical neural networks two field pattern recognition two field function approximation exercise briefly characterize four development phases neural networks give expressive examples phase 
[biological, neural, networks] biological systems solve problems system neurons work understand functionality different quantities neurons able nervous system information processing occur short biological overview complexity simple elements neural information processing followed thoughts simplification order technically adapt begin describe technical side neural networks would useful briefly discuss biology neural networks cognition living organisms reader may skip following chapter without missing technical informa tion hand recommend read said excursus want learn something underlying neurophysiology see small approaches technical neural networks caricatures nature powerful natural counterparts must small approaches already effective want take brief look nervous system vertebrates start rough granularity proceed brain neural level reading want recommend books helped lot chapter 
[biological, neural, networks, vertebrate, nervous, system] entire information processing system vertebrate nervous system con sists central nervous system peripheral nervous system first simple subdivision reality rigid subdivision make sense helpful outline information processing body 
[biological, neural, networks, vertebrate, nervous, system, peripheral, central, nervous, system] peripheral nervous system pns comprises nerves situated outside brain spinal cord nerves form branched dense network throughout whole body peripheral nervous system includes example spinal nerves pass spinal cord two within level vertebra spine supply extremities neck trunk also cranial nerves directly leading brain central nervous system cns however main frame within ver tebrate place information received sense organs stored managed furthermore controls inner processes body last least coordinates motor functions organism vertebrate central nervous system consists brain spinal cord fig ever want focus brain purpose simplification divided four areas fig discussed 
[biological, neural, networks, vertebrate, nervous, system, cerebrum, responsible, abstract, thinking, processes] cerebrum telencephalon one areas brain changed evolution along axis running lateral face back head area divided two hemispheres organized folded structure cerebral hemispheres connected one strong nerve cord bar several small ones large number neurons located cerebral cortex cortex approx thick divided different cortical fields specific task fulfill primary cortical fields responsible processing qual itative information management different perceptions visual cortex responsible management vision association cortical fields however perform abstract association thinking processes also contain memory 
[biological, neural, networks, vertebrate, nervous, system, cerebellum, controls, coordinates, motor, functions] cerebellum located cerebrum therefore closer spinal cord accordingly serves less abstract functions higher priority large parts motor coordination performed balance movements controlled errors continually corrected purpose cerebellum direct sensory figure illustration central nervous system spinal cord brain figure illustration brain colored areas brain discussed text turn abstract information processing direct reflexive processing darker areas brain colored information muscle lengths well acoustic visual information also receives messages abstract motor signals coming cerebrum human brain cerebellum considerably smaller cerebrum rather exception many vertebrates ratio less pronounced take look vertebrate evolution notice cerebellum small cerebum large least highly developed structure vertebrate brain two remaining brain areas also briefly discussed diencephalon brainstem 
[biological, neural, networks, vertebrate, nervous, system, diencephalon, controls, fundamental, physiological, processes] interbrain diencephalon includes parts thalamus briefly discussed part diencephalon mediates sensory motor signals cerebrum particularly thalamus decides part information transferred cerebrum especially less important sensory perceptions suppressed short notice avoid overloads another part diencephalon hypothalamus controls number processes within body diencephalon also heavily involved human circadian rhythm internal clock sensation pain 
[biological, neural, networks, vertebrate, nervous, system, reflexes] comparison diencephalon brainstem truncus cerebri spectively phylogenetically much older roughly speaking extended spinal cord thus connection brain spinal cord brainstem also divided different areas exemplarily introduced chapter functions discussed abstract functions towards fundamental ones one important component pons bridge kind transit station many nerve signals brain body vice versa pons damaged cerebral infarct result could locked syndrome condition patient walled within body conscious aware loss cognitive function cannot move commu nicate means senses sight hearing smell taste generally working perfectly normal locked patients may often able communicate others blinking moving eyes furthermore brainstem responsible many fundamental reflexes blinking reflex coughing parts nervous system one thing common information processing accomplished huge accumulations billions similar cells whose structure simple communicate continuously large groups cells send coordinated signals thus reach enormous information processing capacity familiar brain leave level brain areas continue cellular level body level neurons 
[biological, neural, networks, neurons, information, processing, cells] specifying functions processes within neuron give rough description neuron functions neuron nothing switch infor mation input output switch activated enough stimuli neurons hitting information input information output pulse sent example neurons figure illustration biological neuron components discussed text 
[biological, neural, networks, neurons, information, processing, cells, components, neuron] want take look components neuron fig follow way electrical information takes within neuron dendrites neuron receive information special connections synapses synapses weight individual parts information incoming signals neurons cells transferred neuron special connections synapses connections usually found dendrites neuron sometimes also directly soma distinguish electrical chemical synapses electrical synapse simpler variant electrical signal received synapse coming presynaptic side directly transferred postsy naptic nucleus cell thus direct strong unadjustable connection signal transmitter signal receiver example relevant shortening reactions must hard coded within living organism chemical synapse distinctive variant electrical coupling source target take place coupling interrupted synaptic cleft cleft electrically separates presynaptic side postsynaptic one might think nevertheless information flow discuss happens electrical chemical process presynaptic side synaptic cleft electrical signal converted chemical signal process induced chemical cues released called neurotransmitters neurotransmitters cross synaptic cleft transfer information nucleus cell simple explanation later see exactly works reconverted electrical information neurotransmitters degraded fast possible release precise information pulses spite complex functioning chemical synapse compared electrical synapse utmost advantages one way connection chemical synapse one way connection due fact direct electrical connection pre postsynaptic area electrical pulses postsynaptic area cannot flash presynap tic area adjustability large number different neurotransmitters also released various quantities synaptic cleft neurotransmitters stimulate postsynaptic cell nucleus others slow stimulation synapses transfer strongly stimulating signal weakly stimulating ones adjustability varies lot one central points examination learning ability brain synapses variable time form stronger weaker connection dendrites collect parts information dendrites branch like trees cell nucleus neuron called soma receive electrical signals many different sources transferred nucleus cell amount branching dendrites also called dendrite tree soma weighted information accumulated cell nucleus soma received plenty activating stimulating inhibiting diminishing signals synapses dendrites soma accumulates signals soon accumulated signal exceeds certain value called threshold value cell nucleus neuron activates electrical pulse trans mitted neurons connected current one axon transfers outgoing pulses pulse transferred neurons means axon axon long slender extension soma extreme case axon stretch one meter within spinal cord axon electrically isolated order achieve better conduction electrical signal return point later leads dendrites transfer information example neurons back beginning description neuron elements axon however transfer information kinds cells order control 
[biological, neural, networks, neurons, information, processing, cells, electrochemical, processes, neuron, components] pursued path electrical signal dendrites via synapses nucleus cell via axon dendrites want take small step biology towards technology simplified introduction electrochemical information processing provided neurons maintain electrical membrane potential one fundamental aspect fact compared environment neurons show difference electrical charge potential membrane envelope neuron charge different charge outside difference charge central concept important understand processes within neuron difference called membrane potential membrane potential difference charge created several kinds charged atoms ions whose concentration varies within outside neuron penetrate membrane inside outwards find certain kinds ions often less often inside descent ascent concentration called concentration gradient let first take look membrane potential resting state neuron assume electrical signals received outside case membrane potential since learned potential depends concentration gradients various ions course central question maintain concentration gradients normally diffusion predominates therefore ion eager decrease concentration gradients spread evenly happens membrane potential move towards finally would membrane potential anymore thus neuron actively maintains membrane potential able process information work secret membrane permeable ions others maintain potential various mechanisms progress time concentration gradient described ions try uniformly distributed possible concentration ion higher inside neuron outside try diffuse outside vice versa positively charged ion potassium occurs frequently within neuron less frequently outside neuron therefore slowly diffuses neuron membrane another group negative ions collectively called remains within neuron since membrane permeable thus inside neuron becomes negatively charged negative ions remain positive ions disappear inside cell becomes negative result another gradient electrical gradient electrical gradient acts contrary concentration gradi ent intracellular charge strong therefore attracts positive ions wants get back cell two gradients left alone would eventually balance reach steady state membrane potential would develop want achieve resting membrane potential thus seem exist disturbances prevent furthermore another important ion sodium membrane permeable however slowly pours membrane cell result sodium driven cell one hand less sodium within neuron outside neuron hand sodium positively charged interior cell negative charge second reason sodium wanting get cell due low diffusion sodium cell intracellular sodium concentration increases time inside cell becomes less negative pours slowly see complex mechanism everything influenced everything sodium shifts intracellular equilibrium negative less negative compared environment even two ions standstill gradients balanced could still achieved last piece puzzle gets game pump rather protein atp actively transports ions direction actually want take sodium actively pumped cell although tries get cell along concentration gradient electrical gradient potassium however diffuses strongly cell actively pumped back reason pump also called sodium potassium pump pump main tains concentration gradient sodium well potassium sort steady state equilibrium created finally resting potential observed membrane potential maintained fact membrane impermeable ions ions actively pumped concentration electrical gradients know neuron membrane potential want observe neuron receives transmits signals neuron activated changes membrane potential learned sodium potassium diffuse membrane sodium slowly potassium faster move channels within membrane sodium potassium channels addition permanently open channels responsible diffusion balanced sodium potassium pump also exist channels always open response required since opening channels changes concentration ions within outside membrane also changes membrane potential controllable channels opened soon accumulated received stimulus exceeds certain threshold example stimuli received neurons causes exist example specialized forms neurons sensory cells light incidence could stimulus incoming amount light exceeds threshold controllable channels opened said threshold threshold potential lies soon received stimuli reach value neuron activated electrical signal action potential initiated signal transmitted cells connected observed neuron cells listen neuron want take closer look different stages action potential fig resting state permanently open sodium potassium channels per meable membrane potential actively kept neuron figure initiation action potential time stimulus threshold stimulus opens channels sodium pour intracellular charge becomes positive soon membrane potential exceeds threshold action potential initiated opening many sodium channels depolarization sodium pouring remember sodium wants pour cell lower intracellular extracellular concentration sodium additionally cell dominated negative environment attracts positive sodium ions massive influx sodium drastically increases membrane potential approx electrical pulse action potential repolarization sodium channels closed potassium channels opened positively charged ions want leave positive interior cell additionally intracellular concentration much higher extracellular one increases efflux ions even interior cell negatively charged exterior hyperpolarization sodium well potassium channels closed first membrane potential slightly negative resting potential due fact potassium channels close slowly result posi tively charged potassium effuses lower extracellular concentration refractory period resting state established neuron react newly applied stimuli action potential simple terms refractory period mandatory break neuron take order regenerate shorter break often neuron fire per time resulting pulse transmitted axon axon pulse conducted saltatory way already learned axon used transmit action potential across long distances remember find illustration neuron including axon fig axon long slender extension soma vertebrates normally coated myelin sheath consists schwann cells pns oligodendrocytes cns insulate axon well electrical activity distance gaps cells schwann cells well oligodendrocytes varieties glial cells times glial cells neurons surround neurons glia glue insulate provide energy etc called nodes ranvier said gaps appear one insulate cell ends next one begins obvious node axon less insulated may assume less insulated nodes disadvantage axon however nodes mass transferred intracellular extracellular area transfer impossible parts axon situated two nodes internodes therefore insulated myelin sheath mass transfer permits generation signals similar generation action potential within soma action potential transferred follows continuously travel along axon jumps node node thus series depolarization travels along nodes ranvier one action potential initiates next one mostly even several nodes active time pulse jumping node node responsible name pulse conductor saltatory conductor obviously pulse move faster jumps larger axons large intern odes achieve signal dispersion approx meters per second however internodes cannot grow indefinitely since action potential transferred would fade much reaches next node nodes task constantly amplify signal cells receiving action potential attached end axon often connected dendrites synapses already indicated action potentials generated information received dendrites neurons 
[biological, neural, networks, receptor, cells, modified, neurons] action potentials also generated sensory information organism receives environment sensory cells specialized receptor cells able perceive specific stimulus energies light temperature sound existence certain molecules like example sense smell working fact sensory cells actually modified neurons receive electrical signals via dendrites existence stimulus specific receptor cell ensures ion channels open action potential developed process transforming stimulus energy changes membrane potential called sensory transduction usually stimulus energy weak directly cause nerve signals therefore signals amplified either transduction means stimulus conducting apparatus resulting action potential processed neurons transmitted thalamus already learned gateway cerebral cortex therefore reject sensory impressions according current relevance thus prevent abundance information managed 
[biological, neural, networks, receptor, cells, modified, neurons, different, receptor, cells, various, types, perceptions] primary receptors transmit pulses directly nervous system good example sense pain stimulus intensity proportional amplitude action potential technically amplitude modulation secondary receptors however continuously transmit pulses pulses control amount related neurotransmitter responsible transferring stimulus stimulus turn controls frequency action potential receiving neuron process frequency modulation encoding stimulus allows better perceive increase decrease stimulus individual receptor cells cells forming complex sensory organs eyes ears receive stimuli within body means interoceptors well stimuli outside body means exteroceptors outlined information received environment interesting look information processed 
[biological, neural, networks, receptor, cells, modified, neurons, information, processed, every, level, nervous, system] reason believe received information transmitted brain processed brain ensures output form motor pulses thing organism actually within environment move information processing entirely decentralized order illustrate principle want take look examples leads abstract fundamental hierarchy information processing certain information processed cerebrum developed natural information processing structure midbrain thalamus serves already learned gateway cerebral cortex situated much lower hierarchy filtering information respect current relevance executed midbrain important method information processing even thalamus receive preprocessed stimuli outside let continue lowest level sensory cells lowest level receptor cells information received transferred directly processed one main aspects subject prevent transmission continuous stimuli central nervous system sensory adaptation due continuous stimulation many receptor cells automatically become insensitive stimuli thus receptor cells direct mapping specific stimulus energy onto action potentials depend past sensors change sensitivity according situation taste receptors respond less stimulus according nutritional condition organism even stimulus reaches receptor cells information processing already executed preceding signal carrying apparatus example form amplification external internal ear specific shape amplify sound also allows association sensory cells sense hearing sensory stimulus increase logarithmically intensity heard signal closer examination necessary since sound pressure signals ear constructed vary wide exponential range logarithmic measurement advantage firstly overload prevented secondly fact intensity measurement intensive signals less precise matter well jet fighter starting next small changes noise level ignored get feeling sensory organs information processing organism briefly describe usual light sensing organs organs often found nature third light sensing organ described single lens eye discuss information processing eye 
[biological, neural, networks, receptor, cells, modified, neurons, outline, common, light, sensing, organs] many organisms turned extremely useful able perceive electro magnetic radiation certain regions spectrum consequently sensory organs developed detect electromagnetic radiation wave length range radiation perceivable human eye called visible range simply light different wavelengths electromagnetic radiation perceived human eye different colors visible range electromagnetic radia tion different organism organisms cannot see colors wavelength ranges see others even perceive additional wavelength ranges range begin human order get broader knowl edge sense sight briefly want look two organs sight evolutionary point view exist much longer human figure compound eye robber fly compound eyes pinhole eyes provide high temporal spatial resolution let first take look called compound eye fig example common insects crustaceans compound eye consists great number small individual eyes look compound eye outside individual eyes clearly visible arranged hexagonal pattern individual eye nerve fiber connected insect brain since individual eyes distinguished obvious number pixels spatial resolution compound eyes must low image blurred compound eyes advantages especially fast flying insects certain compound eyes process images per second human eye however movies images per second appear fluent motion pinhole eyes example found octopus species work guess similar pinhole camera pinhole eye small opening light entry projects sharp image onto sensory cells behind thus spatial resolution much higher compound eye due small opening light entry resulting image less bright single lens eyes combine advantages two eye types complex light sensing organ common vertebrates single lense eye resulting image sharp high resolution image environment high variable light intensity hand complex similar pinhole eye light enters opening pupil projected onto layer sensory cells eye retina contrast pinhole eye size pupil adapted lighting conditions means iris muscle expands contracts pupil differences pupil dilation require actively focus image therefore single lens eye contains additional adjustable lens retina receive information also responsible information processing light signals falling eye received retina directly preprocessed several layers information processing cells want briefly discuss dif ferent steps information processing follow way information carried light photoreceptors receive light signal und cause action potentials different receptors different color components light intensities receptors real light receiving part retina sensitive extent one single photon falling retina cause action potential several photoreceptors transmit signals one single bipolar cell means information already summarized nally transformed light signal travels several bipolar cells ganglion cells various bipolar cells transmit information one ganglion cell higher number photoreceptors affect ganglion cell larger field perception receptive field covers ganglions less sharp image area ganglion cell information already reduced directly retina overall image example blurred peripheral field vision far learned information processing retina top structure want take look different kinds bipolar cells well discuss would far horizontal amacrine cells cells connected front back wards laterally allow light signals influence laterally directly information processing retina much pow erful method information processing compressing blurring horizontal cells excited photoreceptor able excite nearby photoreceptors time inhibit distant bipolar cells receptors ensures clear perception outlines bright points amacrine cells intensify certain stimuli distributing information bipolar cells several ganglion cells inhibiting ganglions first steps transmitting visual information brain show information processed first moment information received hand processed parallel within millions information processing cells system power resistance errors based upon massive division work 
[biological, neural, networks, amount, neurons, living, stages, development] overview different organisms neural capacity large part neurons required nervous system nematode worm serves popular model organism biology nematodes live soil feed bacteria neurons make ant simplify matters neglect fact ant species also less efficient nervous systems due use different attractants odors ants able engage complex social behavior form huge states millions individuals regard ant state individual cognitive capacity similar chimpanzee even human neurons nervous system fly constructed fly evade object real time three dimensional space land upon ceiling upside considerable sensory system compound eyes vib rissae nerves end legs much thus fly considerable differential integral calculus high dimensions implemented hardware know fly easy catch course bodily functions also controlled neurons ignored neurons enough cerebral matter create honeybee honey bees build colonies amazing capabilities field aerial reconnais sance navigation neurons result mouse world vertebrates already begins neurons sufficient rat animal denounced tremely intelligent often used participate variety intelligence tests representative animal world rats extraordinary sense smell orientation also show social behavior brain frog positioned within dimension frog complex build many functions swim evolved complex behavior frog continuously target said fly means eyes jumping three dimensional space catch tongue considerable probability neurons make bat bat navigate total darkness room exact several centimeters using sense hearing uses acoustic signals localize self camouflaging insects moths certain wing structure reflects less sound waves echo small also eats prey flying neurons required brain dog companion man ages take look another popular companion man neurons found cat twice much dog know cats elegant patient carnivores show variety behaviors way octopus positioned within magnitude people know example labyrinth orientation octopus vastly superior rat neurons already get chimpanzee one animals similar human neurons make human usually human considerable cognitive capabil ities able speak abstract remember use tools well knowledge humans develop advanced technologies manifold social structures neurons nervous systems neurons man nervous system mention elephants certain whale species state art computers able keep aforementioned process ing power fly recent research results suggest processes nervous systems might vastly powerful people thought long ago michaeva describe separate synapse integrated information way information process ing posterity show right 
[biological, neural, networks, transition, technical, neurons, neural, networks, living, caricature, biology] change biological neural networks technical ones radical simplification want briefly summarize conclusions relevant technical part learned biological neurons linked weighted way stimulated electrically transmit signal via axon axon directly transferred succeeding neurons first cross synaptic cleft signal changed variable chemical processes receiving neuron various inputs post processed synaptic cleft summarized accumulated one single pulse depending neuron stimulated cumulated input neuron emits pulse thus output non linear proportional cumulated input brief summary corresponds exactly elements biological neural networks want take technical approximation vectorial input input technical neurons consists many components fore vector nature neuron receives pulses neurons average scalar output output neuron scalar means neuron consists one component several scalar outputs turn form vectorial input another neuron particularly means somewhere neuron various input components summarized way one component remains synapses change input technical neural networks inputs preprocessed multiplied number weight weighted set weights represents information storage neural network biological original technical adaptation accumulating inputs biology inputs summarized pulse according chemical change accumulated technical side often realized weighted sum get know later means accumulation continue one value scalar instead vector non linear characteristic input technical neurons also proportional output adjustable weights weights weighting inputs variable similar chemical processes synaptic cleft adds great dynamic net work large part knowledge neural network saved weights form power chemical processes synaptic cleft current casually formulated simple neuron model receives vectorial input components multiplied appropriate weights accumu lated aforementioned term called weighted sum nonlinear mapping defines scalar output transition want specify precisely neuron model add odds ends afterwards take look weights adjusted 
[biological, neural, networks, exercises] exercise estimated human brain consists approx nerve cells synapses exercise assume synapses per neuron let assume single synapse could save bits information naïvely calculated much storage capacity brain note information neuron connected neuron also important 
[components, artificial, neural, networks] formal definitions colloquial explanations components realize technical adaptations biological neural networks initial descriptions combine components neural network chapter contains formal definitions neural network components used later text chapter able read individual chapters work without know preceding ones although would useful 
[components, artificial, neural, networks, concept, time, neural, networks] definitions text use term time number cycles neural network respectively time divided discrete time steps definition concept time current time present time referred next time step preceding one time steps referred analogously following chapters several mathematical variables net refer certain point time notation example net biological point view course plausible human brain neuron wait another one significantly simplifies imple mentation 
[components, artificial, neural, networks, components, neural, networks] output function neuron calculates values transferred neurons connected formally definition output function let neuron output function calculates output value neuron activation state generally output function defined globally often function identity activation directly output unless explicitly specified differently use identity output function within text definitions output functions may useful range values activation function sufficient heaviside function fermi function temperature parameter tanh hyperbolic tangent figure various popular activation functions top bottom heaviside binary threshold function fermi function hyperbolic tangent fermi function expanded temperature parameter original fermi function represented dark colors temperature parameters modified fermi functions ordered ascending steepness und 
[components, artificial, neural, networks, components, neural, networks, connections, carry, information, processed, neurons] data transferred neurons via connections connecting weight either excitatory inhibitory definition connections already included definition neural network snipe connection weights set using method neuralnetwork setsynapse 
[components, artificial, neural, networks, components, neural, networks, propagation, function, network, inputs] looking neuron usually find lot neurons connection transfer output neuron propagation function receives outputs neurons connected transforms consideration connecting weights network input net processed activation function thus network input result propagation function definition propagation function network input let set neurons network input called net calculated propagation function prop follows net prop weighted sum popular multiplication output neuron summation results net snipe propagation function snipe implemented using weighted sum 
[components, artificial, neural, networks, components, neural, networks, activation, switching, status, neuron] based model nature every neuron certain extent times active excited whatever call reactions neurons input values depend activation state activation state indicates extent neu ron activation often shortly referred activation formal definition included following definition activation function generally defined follows definition activation state activation general let neuron activation state short activation explicitly assigned indicates extent neuron activity results activation function snipe possible get set activation states neurons using methods getactivation setactivation class neuralnetwork 
[components, artificial, neural, networks, components, neural, networks, threshold, value] near threshold value activation function neuron reacts particularly sen sitive biological point view threshold value represents threshold neuron starts firing threshold value also mostly included definition activation function generally definition following definition threshold value general let neuron threshold value uniquely assigned marks position maximum gradient value activation function 
[components, artificial, neural, networks, components, neural, networks, dependent, network, input, treshold, value] certain time already learned activation neuron depends previous activation state neuron external input definition activation function activation let neuron acti vation function defined act net transforms network input net well previous activation state new activation state threshold value playing important role already mentioned previous activation always relevant current see examples variants unlike variables within neural network particularly unlike ones defined far activation function often defined globally neurons least set neurons threshold values different neuron also keep mind threshold values changed example learning procedure particular become necessary relate threshold value time write instance reasons clarity omitted activation function also called transfer function snipe snipe activation functions generalized neuron behaviors behaviors represent normal activation functions even incorporate internal states dynamics corresponding parts snipe found package neuronbehavior also contains activation functions introduced next section interface neuronbehavior allows implementation custom behaviors objects inherit interface passed neuralnetworkdescriptor instance possible define individual behaviors per neuron layer 
[components, artificial, neural, networks, components, neural, networks, common, activation, functions] simplest activation function binary threshold function fig take two values also referred heaviside function input certain threshold function changes one value another otherwise remains constant implies function differentiable threshold rest derivative due fact backpropagation learning example impossible see later also popular fermi function logistic function fig maps range values hyperbolic tangent fig maps functions differentiable fermi function expanded temperature parameter form smaller parameter compress function axis thus one arbitrarily approximate heaviside function incidentally exist activation functions explicitly defined depend input according random distribution stochastic activation function alternative hypberbolic tangent really worth mentioning sug gested anguita tired slowness worksta tions back thinking make neural network propagations faster quickly identified approximation function used hyperbolic tangent one causes slowness consequently engineered approx imation hyperbolic tangent using two parabola pieces two half lines price delivering slightly smaller range values hyperbolic tangent instead dependent cpu one uses calculated times faster needs two multiplications one addition advantages mentioned later snipe activation functions introduced implemented within classes fermi tangenshyperbolicus located package neuronbehavior fast hyperbolic tangent approximation located within class tangenshyperbolicusanguita 
[components, artificial, neural, networks, components, neural, networks, learning, strategies, adjust, network, fit, needs] since address subject later detail first want get know principles neural network structures provide brief general definition definition general learning rule learning strategy algorithm used change thereby train neural network network produces desired output given input 
[components, artificial, neural, networks, network, topologies] become acquainted composition elements neural network want give overview usual topologies designs neural networks construct networks consisting elements every topology described text illustrated map hinton diagram reader immediately see characteristics apply networks hinton diagram dotted weights represented light grey fields solid ones dark grey fields input output arrows added reasons clarity cannot found hinton diagram order clarify connections line neurons column neurons inserted small arrow upper left cell snipe snipe designed realization arbitrary network topologies respect snipe defines different kinds synapses depending source target kind synapse separately allowed forbidden set networks using setallowed methods neuralnetworkdescriptor instance 
[components, artificial, neural, networks, network, topologies, feedforward, layer, consist, layers, connection, towards, following, layer] feedforward text feedforward networks fig networks first explore even use different topologies later neurons grouped following layers one input layer hidden pro cessing layers invisible outside neurons also referred hidden neurons one output layer feedforward network neuron one layer directed connections neurons next layer towards output layer fig connections permitted feedforward gfed abc gfed abc ttiiiii iiiii iiiii iiiii iiiii gfed abc gfed abc gfed abc ttiiiii iiiii iiiii iiiii iiiii gfed abc gfed abc figure feedforward network three layers two input neurons three hidden neurons two output neurons characteristic hinton diagram completely linked feedforward networks formation blocks diagonal network represented solid lines often confronted feedforward networks every neuron connected neurons next layer layers called completely linked prevent naming conflicts output neurons often referred definition feedforward network neuron layers feedforward network fig clearly separated one input layer one output layer one processing layers invisible outside also called hidden layers con nections permitted neurons following layer gfed abc gfed abc gfed abc gfed abc gfed abc gfed abc gfed abc figure feedforward network shortcut connections represented solid lines right side feedforward blocks new connections added hinton diagram shortcut connections skip layers feedforward networks permit called shortcut connections fig con nections skip one levels connections may directed towards output layer definition feedforward network shortcut connections similar feedforward network connections may directed towards next layer also towards subsequent layer 
[components, artificial, neural, networks, network, topologies, recurrent, networks, influence] recurrence defined process neuron influencing means connection recurrent networks always explicitly defined input output neurons therefore figures omitted markings concern matter numbered neurons direct recurrences start end neuron networks allow neurons connected called direct recurrence sometimes self recurrence fig result neurons inhibit therefore strengthen order reach activation limits definition direct recurrence expand feedforward network connecting neuron weights connections referred words diagonal weight matrix may different indirect recurrences influence starting neuron making detours connections allowed towards input layer called indirect currences neuron use indirect forwards connections influence example influencing neurons next layer neurons next layer influencing fig definition indirect recurrence network based feedforward network additional connections neurons preceding layer allowed therefore diagonal different lateral recurrences connect neurons within one layer connections neurons within one layer called lateral recurrences fig neuron often inhibits neurons layer strengthens result strongest neuron becomes active winner takes scheme figure network similar feedforward network directly recurrent neurons direct recurrences represented solid lines exactly correspond diagonal hinton diagram matrix figure network similar feedforward network indirectly recurrent neurons indirect recurrences represented solid lines see connections preceding layers exist fields symmetric feedforward blocks hinton diagram occupied figure network similar feedforward network laterally recurrent neurons direct recurrences represented solid lines recurrences exist within layer hinton diagram filled squares concentrated around diagonal height feedforward blocks diagonal left uncovered definition lateral recurrence laterally recurrent network permits connec tions within one layer 
[components, artificial, neural, networks, network, topologies, completely, linked, networks, allow, possible, connection] completely linked networks permit connections neurons except direct recurrences furthermore connections must symmetric fig popular example self organizing maps introduced chapter definition complete interconnection case every neuron always allowed connected every neuron result every neuron become input neuron therefore direct recurrences normally cannot applied xegt uujjjjj jjjjj jjjjj jjjjj jjj xegt uujjjjj jjjjj jjjjj jjjjj jjj figure completely linked network symmetric connections without direct recur rences hinton diagram diagonal left blank clearly defined layers longer exist thus matrix may unequal everywhere except along diagonal 
[components, artificial, neural, networks, values, bias, neuron, technical, trick, consider, threshold, values, connection, weights] know many network paradigms neurons threshold value indicates neuron becomes active thus threshold value activation function parameter neuron biological point view sounds plausible complicated access activation function runtime order train threshold value threshold values neurons also realized connecting weight continuously firing neuron purpose additional bias neuron whose output value always integrated network connected neurons new connections get weights get negative threshold values definition bias neuron neuron whose output value always represented gfed abc bias used represent neuron biases connection weights enables weight training algorithm train biases time threshold value neurons set threshold values implemented connection weights fig directly trained together connection weights considerably facilitates learning process words instead including threshold value activation function included propagation function even shorter threshold value subtracted network input part network input formally let neurons threshold values inserting bias neuron whose output value always generating connections said bias neuron neurons weighting connections bias bias set receive equivalent neural network whose threshold values realized connection weights undoubtedly advantage bias neuron fact much easier plement network one disadvantage representation network already becomes quite ugly neurons let alone great number way bias neuron often referred neuron bias neuron omitted clarity following illustrations know exists threshold values simply treated weights snipe snipe bias neuron implemented instead neuron individual biases neuron index bias neuron gfed abc gfed abc gfed abc gfed abc bias figure two equivalent neural networks one without bias neuron left one bias neuron right neuron threshold values found neurons connecting weights connections furthermore omitted weights already existing connections represented dotted lines right side 
[components, artificial, neural, networks, representing, neurons] already seen either write name threshold value neuron another useful representation use several times following illustrate neurons according type data processing see fig examples without explanation different types neurons explained soon need 
[components, artificial, neural, networks, take, care, order, which, neuron, activations, calculated] neural network important order individual neurons receive process input output results distinguish two model classes 
[components, artificial, neural, networks, take, care, order, which, neuron, activations, calculated, synchronous, activation] neurons change values synchronously simultaneously calculate network inputs activation output pass synchronous activation wvut pqrs gauß gfed abc onml hijk wvut pqrs wvut pqrs tanh wvut pqrs fermi onml hijk act gfed abc bias figure different types neurons appear following text corresponds closest biological counterpart implemented hardware useful certain parallel computers especially feedforward networks order activation generic used networks arbitrary topology definition synchronous activation neurons network calculate network inputs time means propagation function activation means activation function output means output function activation cycle complete snipe implementing software one could model general activation order every time step calculating caching every single network input calculating activations exactly done snipe snipe able realize arbitrary network topologies 
[components, artificial, neural, networks, take, care, order, which, neuron, activations, calculated, asynchronous, activation] neurons change values simultaneously different points time exist different orders want introduce following random order definition random order activation random order activation neuron randomly chosen net updated neurons cycle fold execution step obviously neurons repeatedly updated one cycle others however apparently order activation always useful random permutation random permutation neuron chosen exactly random order one cycle definition random permutation initially permutation neurons calculated randomly therefore defines order activation neurons successively processed order order activation well used rarely firstly order generally useless secondly time consuming compute new permutation every cycle hopfield network chapter topology nominally random randomly permuted order activation note practice previously mentioned reasons fixed order activation preferred orders either previous neuron activations time already existing neuron activations time calculating activations taken starting point topological order definition topological activation topological order activation neurons updated one cycle according fixed order order defined network topology procedure considered non cyclic non recurrent networks since otherwise order activation thus feedforward networks procedure reasonable input neurons would updated first inner neurons finally output neurons may save lot time given synchronous activation order feedforward network layers neurons would need full propagation cycles order enable input data influence output network given topological activation order need one single propagation however every network topology allows finding special activation order enables saving time snipe want use snipe implementing feedforward networks may save calculation time using feature fastprop mentioned within documentation class neuralnetworkdescriptor fastprop enabled cause data propagation carried slightly different way standard mode net inputs calculated first followed activations fastprop mode every neuron activation calculated right net input neuron values calculated ascending neuron index order neuron numbers ascending input output layer provides perfect topological activation order feedforward networks fixed orders activation implementation obviously fixed orders activation defined well therefore implementing instance feedforward networks popular determine order activation according topology use order without verification runtime necessarily useful networks capable change topology 
[components, artificial, neural, networks, communication, outside, world, input, output, data, neural, networks] finally let take look fact course many types neural networks permit input data data processed produce output let example regard feedforward network shown fig two input neurons two output neurons means also two numerical inputs outputs simplification summarize input output components input output neurons within vectors definition input vector network input neurons needs inputs considered input vector conse quence input dimension referred data put neural network using components input vector network inputs input neurons definition output vector network output neurons provides outputs regarded output vector thus output dimension referred data output neural network output neurons adopting components output vector output values snipe order propagate data neuralnetwork instance propagate method used receives input vector array doubles returns output vector way defined closely examined basic components neural networks without seen network action first continue theoretical explanations generally describe neural network could learn 
[components, artificial, neural, networks, exercises] exercise would useful point view insert one bias neuron layer layer based network feedforward network discuss relation representation implementation network result network change exercise show fermi function well hyperbolic tangent tanh derivatives expressed respective functions two statements tanh tanh true 
[samples] approaches thoughts teach machines neural networks corrected encouraged even learn without help thoughts want change learning procedure change measurement errors learned enough written interesting characteristic neural networks capa bility familiarize problems means training sufficient training able solve unknown problems class approach referred generalization introducing specific learning procedures want propose basic principles learning procedure chapter 
[samples, different, paradigms, learning] learning comprehensive term learning system changes order adapt environmental changes neural network could learn many things course always question implement principle neural network changes components changing learned theoretically neural network could learn developing new connections deleting existing connections changing connecting weights changing threshold values neurons varying one three neuron functions remember activation function propagation function output function developing new neurons deleting existing neurons course existing connections mentioned assume change weight common procedure furthermore deletion connections realized additionally taking care connection longer trained set moreover develop connections setting non existing connection value connection matrix value different modification threshold values refer possibility implementing weights section thus perform first four learning paradigms training synaptic weights change neuron functions difficult implement intuitive exactly biologically motivated therefore popular omit topic possibilities develop delete neurons provide well justed weights training neural network also optimize network topology thus attract growing interest often realized using evolu tionary procedures since accept large part learning possibilities already covered changes weight also subject matter text however planned extend text towards aspects training snipe methods class neuralnetwork allow changes connection weights addition removal connections neurons methods neuralnetworkdescriptor enable change neuron behaviors respectively activation functions per layer thus let neural network learn modifying connecting weights according rules formulated algorithms therefore learning procedure always algorithm easily implemented means programming language later text assume definition term desired output worth learning known define formally training pattern training set learning samples let training set defined follows definition training set training set named set training patterns use train neural net introduce three essential paradigms learning presenting differ ences regarding training sets 
[samples, different, paradigms, learning, learning, aides] unsupervised learning biologically plausible method suitable problems input patterns given network tries identify similar patterns classify similar categories definition unsupervised learning training set consists input patterns network tries detect similarities generate pattern classes want refer popular example kohonen self organising maps chapter 
[samples, different, paradigms, learning, whether, behaves, well, bad] reinforcement learning network receives logical real value com pletion sequence defines whether result right wrong intuitively clear procedure effective unsupervised learning since network receives specific critera problem solving definition reinforcement learning training set consists input patterns completion sequence value returned network indicating whether result right wrong possibly right wrong 
[samples, different, paradigms, learning, appropriate, desired, outputs] supervised learning training set consists input patterns well correct results form precise activation output neurons thus training set fed network output instance directly compared correct solution network weights changed according difference objective change weights effect network cannot associate input output patterns independently training provide plausible results unknown similar input patterns generalises definition supervised learning training set consists input patterns correct results network receive precise error vector returned learning procedure always biologically plausible extremely effective therefore practicable first want look supervised learning procedures general text corresponding following steps entering input pattern activation input neurons forward propagation input network generation output comparing output desired output teaching input provides error vector difference vector corrections network calculated based error vector corrections applied 
[samples, different, paradigms, learning, offline, online, learning] must noted learning offline set training samples presented weights changed total error calculated means error function operation simply accumulated see also section online every sample presented weights changed procedures advantages disadvan tages discussed learning procedures section necessary offline training procedures also called batch training procedures since batch results corrected training section whole batch training samples including related change weight values called epoch definition offline learning several training patterns entered network errors accumulated learns patterns time definition online learning network learns directly errors training sample term error vector defined section mathematical formalisation learning discussed 
[samples, different, paradigms, learning, questions, answer, learning] application schemes certainly requires preliminary thoughts questions want introduce check list possible answer course text learning input come form must weights modified allow fast reliable learning success learning process measured objective way possible determine best learning procedure possible predict learning procedure terminates whether reach optimal state finite time example oscillate different states learned patterns stored network possible avoid newly learned patterns destroy previously learned associations called stability plasticity dilemma see questions cannot generally answered discussed learning procedure network topology individually 
[samples, training, patterns, teaching, input] get know first learning rule need introduce teaching input case supervised learning assume training set consisting training patterns corresponding correct output values want see output neurons training network finished training long generating wrong outputs output values referred teaching input neuron individually thus neuron incorrect output teaching input means correct desired output training pattern definition training patterns training pattern input vector components whose desired output known entering training pattern network receive output compared teaching input desired output set training patterns called contains finite number ordered pairs training patterns corresponding desired output training patterns often simply called patterns referred literature well text called synonymously patterns training samples etc definition teaching input let output neuron teaching input desired correct value output input certain training pattern analogously vector teaching inputs neurons also combined vector always refers specific training pattern already mentioned contained set training patterns snipe classes relevant training data located package training class trainingsamplelesson allows storage training patterns teaching inputs well simple preprocessing training data definition error vector several output neurons differ ence output vector teaching input training input    referred error vector sometimes also called difference vector depend ing whether learning offline online difference vector refers specific training pattern error set training patterns normalized certain way want briefly summarize vectors yet defined input vector entered neural network depending type network used neural network output output vector basically training sample nothing input vector use training purposes know corresponding teaching input nothing desired output vector training sample error vector difference teaching input actural output general network operation network training training try bring close possible one advice concerning notation referred output values neuron thus output output neuron called output values network referred certainly network outputs neuron outputs outputs output neurons respect true 
[samples, using, training, samples] seen learn principle steps required take look selection training data learning curve successful learning particularly interesting whether network memorized whether use training samples quite exactly produce right output provide wrong answers problems class suppose want network train mapping therefor use training samples fig could chance finally network exactly mark colored areas around training samples output fig top otherwise output thus sufficient storage capacity concentrate six training samples output implies oversized network much free storage capacity hand network could insufficient capacity fig bottom rough presentation input data correspond good generalization performance desire thus find balance fig middle 
[samples, using, training, samples, useful, divide, set, training, samples] often proposed solution problems divide training set one training set really used train one verification set test progress figure visualization training results training set networks capacity high top correct middle low bottom provided enough training samples usual division relations instance training data verification data randomly chosen finish training network provides good results training data well verification data snipe method splitlesson within class trainingsamplelesson allows splitting trainingsamplelesson respect given ratio note verification data provide poor results modify network structure data provide good results otherwise run risk tailoring network verification data means data included training even used explicitly training solution third set validation data used validation supposably successful training training less patterns obviously withhold information network risk worsen learning performance text exact repro duction given samples successful generalization approximation whole function definitely useful train less information network 
[samples, using, training, samples, order, pattern, representation] find different strategies choose order pattern presentation patterns presented random sequence guarantee patterns learned equally well however standard method always sequence patterns hand provokes patterns memorized using recurrent networks later learn type networks random permutation would solve problems already mentioned time consuming calculate permutation snipe method shufflesamples located class trainingsamplelesson permutes lesson 
[samples, learning, curve, error, measurement] learning curve indicates progress error determined various ways motivation create learning curve curve indicate whether network progressing error normalized represent distance measure correct current output network example take pattern specific squared error prefactor also going use derive backpropagation error let output neurons set output neurons err definition specific error specific error err based single training sample means generated online additionally root mean square abbreviated rms euclidean dis tance often used euclidean distance generalization theorem pythagoras useful lower dimensions still visualize usefulness definition euclidean distance euclidean distance two vectors defined err generally root mean square commonly used since considers extreme outliers greater extent definition root mean square root mean square two vectors defined err offline learning total error course one training epoch interesting useful err err definition total error total error err based training samples means generated offline analogously generate total rms total euclidean distance course whole epoch course possible use types error measurement get used error measurement methods suggest look technical report prechelt report error measurement methods sample problems discussed simmilar suggestion discussion exemplary problems snipe several static methods representing different methods error measurement implemented class errormeasurement depending method error measurement learning curve certainly changes perfect learning curve looks like negative exponential function means proportional fig thus representation learning curve illustrated means logarithmic scale fig second diagram bottom said scaling combination descending line implies exponential descent error network good job problems difficult logarithmic representation err see metaphorically speaking descending line often forms spikes bottom reach limit bit resolution computer network actually learned optimum capable learning typical learning curves show flat areas well show steps sign malfunctioning learning process also see fig well suited representation make slightly decreasing learning curve look good cautious reading literature 
[samples, learning, curve, error, measurement, stop, learning] big question stop learning generally training stopped user front learning computer thinks error small enough indeed easy answer thus give something think however depends objective view comparison several learning curves confidence results example boosted network always reaches nearly final error rate different random initializations repeated ini tialization training provide objective result fehler epoche fehler epoche fehler epoche fehler epoche figure four illustrations show idealized smooth learning curve note alternating logarithmic linear scalings also note small inaccurate spikes visible sharp bend curve first second diagram bottom hand possible curve descending fast beginning longer time learning overtaken another curve indicate either learning rate worse curve high worse curve simply got stuck local minimum first find remember larger error values worse small ones case note many people generate learning curve respect training data surprised things work reasons objectivity clarity forgotten plot verification data second learning curve generally provides values slightly worse stronger oscillation good generalization curve decrease network eventually begins memorize samples shape learn ing curve provide indication learning curve verification samples suddenly rapidly rising learning curve verification data con tinuously falling could indicate memorizing generalization getting poorer poorer point could decided whether network already learned well enough next point two curves maybe final point learning applied procedure called early stopping want remind acting indicators draw conclusions 
[samples, gradient, optimization, procedures] order establish mathematical basis following learning proce dures want explain briefly meant gradient descent backpropagation error learning procedure example involves mathematical basis thus inherits advantages disadvantages gradient descent gradient descent procedures generally used want maximize minimize dimensional functions due clarity illustration fig shows two dimensions principally limit number dimensions gradient vector defined differentiable point function points point exactly towards steepest ascent indicates gradient direction means norm thus gradient generalization derivative multi dimensional functions accordingly negative gradient exactly points towards steepest descent gradient operator referred figure visualization gradient descent two dimensional error function move forward opposite direction steepest descent towards lowest point step width proportional steeper descent faster steps left area shown right steps contour lines shown obvious movement made opposite direction towards minimum function continuously slows proportionally source http webster fhs hagenberg staff sdreisei teaching patternclassification graddescent pdf nabla operator overall notation gradient point two dimensional function definition gradient let gradient vector components defined point differential dimensional function gradient operator notation defined directs point towards steepest ascent point corresponding degree ascent gradient descent means going downhill small steps starting point function towards gradient means vividly speaking direction ball would roll starting point size steps proportional steeper descent longer steps therefore move slowly flat plateau steep ascent run downhill rapidly came valley would depending size steps jump would return figure possible errors gradient descent detecting bad minima quasi standstill small gradient oscillation canyons leaving good minima valley across opposite hillside order come closer closer deepest point valley walking back forth similar ball moving within round bowl definition gradient descent let dimensional function given starting point gradient descent means going direction towards steps size towards smaller smaller values gradient descent procedures errorless optimization procedure see following sections however work still well many problems makes optimization paradigm frequently used anyway let look potential disadvantages keep mind bit 
[samples, gradient, optimization, procedures, gradient, procedures, incorporate, several, problems] already implied section gradient descent therefore backpropaga tion promising foolproof one problem result always reveal error occurred often gradient descents converge suboptimal minima every gradient descent procedure example get stuck within local minimum part fig problem increasing proportionally size error surface universal solution reality one cannot know optimal minimum reached considers training successful acceptable minimum found flat plataeus error surface may cause training slowness passing flat plateau instance gradient also becomes negligibly small hardly descent part fig requires many steps hypothetically possible gradient would completely stop descent even good minima reached may left afterwards hand gradient large steep slope large steps made good minimum possibly missed part fig steep canyons error surface may cause oscillations sudden alternation one strong negative gradient strong positive one even result oscillation part fig nature error occur often think possibilities 
[samples, strategies] looked learning formal point view much yet little time look exemplary problem later use test implemented networks learning rules table illustration parity function three inputs 
[samples, strategies, boolean, functions] popular example one work nineteen sixties xor function need hidden neuron layer discussed detail thus need least two neurons inner layer let activation function layers except input layer course hyperbolic tangent trivially expect outputs depending whether function xor outputs exactly first beginner mistake occurs outputs close close limits hyperbolic tangent case fermi function need large network inputs chance reach network inputs large weights learned learning process largely extended therefore wiser enter teaching inputs desired outputs satisfied network outputs values instead another favourite example singlelayer perceptrons boolean functions 
[samples, strategies, parity, function] parity function maps set bits depending whether even number input bits set basically function characterized easy learnability approx shown table learning effort rapidly increases reader may create score table bit parity function conspicuous figure illustration training samples spiral problem 
[samples, strategies, spiral, problem] training sample function let take two spirals coiled fig function certainly representing mapping one spirals assigned output value spiral memorizing help network understand mapping example solved means mlp 
[samples, strategies, checkerboard, problem] create two dimensional function form specify checkered training samples fig one colored field representing rest representing difficulty increases proportionally size function field easy learn larger fields difficult eventually use methods suitable kind problems mlp spiral problem similar checkerboard problem mathe matically speaking first problem using polar coordinates instead cartesian coordinates want introduce example one last trivial case identity figure illustration training samples checkerboard problem 
[samples, strategies, identity, function] using linear activation functions identity mapping course within parameters used activation function problem network put obstacles way using sigmoid functions would difficult network learn identity try fun time hava look first mathematical learning rule 
[samples, strategies, lots, exemplary, problems] lots lots exemplary problems want recommend technical report written prechelt also named sections error measurement procedures 
[samples, learning, rules] donald hebb formulated hebbian rule basis complicated learning rules discuss text distinguish original form general form kind principle learning rules 
[samples, learning, rules, original, rule] definition hebbian rule neuron receives input neuron neurons strongly active time increase weight strength connection mathematically speaking rule change weight proportional following factors output predecessor neuron well activation successor neuron constant learning rate discussed section changes weight simply added weight speaking twice activation formula using output neuron neuron activation neuron remember identity often used output function therefore neuron often besides hebb postulated rule long specification technical neurons considering learning rule preferred binary activations clear possible activations weights either increase remain constant sooner later would infinitum since corrected upwards error occurs compensated using activations thus weights decreased activation predecessor neuron dissents one successor neuron otherwise increased longer original version hebbian rule 
[samples, learning, rules, generalized, form] learning rules discussed specialization mathematically general form hebbian rule definition hebbian rule general generalized form heb bian rule specifies proportionality change weight product two undefined functions defined input values thus product functions well constant learning rate results change weight see receives output predeces sor cell well weight predecessor successor expects actual desired activation successor stands aforemen tioned teaching input already mentioned specified general definition therefore return path specialization discussed equation short picture learning rule could look like thoughts learning introduced first network paradigm including learning procedure 
[samples, exercises] exercise calculate average value standard deviation following data points 
[perceptron, backpropagation, variants] classic among neural networks talk neural network majority cases speak percepton variation perceptrons multilayer networks without recurrence fixed input output layers description perceptron limits extensions avoid limitations derivation learning procedures discussion problems already mentioned history neural networks perceptron described frank rosenblatt initially rosenblatt defined already discussed weighted sum non linear activation function components perceptron established definition perceptron time term used describe feedforward network shortcut connections network layer scanner neurons retina statically weighted connections following layer called input layer fig weights layers allowed changed neurons subordinate retina pattern detectors initially use binary perceptron every output neuron exactly two possible output values thus binary threshold function used activation function depending threshold value output neuron way binary activation function represents query also negated means negative weights perceptron thus used accomplish true logical information processing gfed abc gfed abc gfed abc gfed abc gfed abc wwooo ooo ooo ooo ooo wvut pqrs gfed abc gfed abc gfed abc gfed abc gfed abc vvnnnn nnnn nnnn nnnn abbildung aufbau eines perceptrons mit einer schicht variabler verbindungen verschiede nen ansichten die durchgezogene gewichtsschicht den unteren beiden abbildungen ist trainier bar oben beispiel der informationsabtastung auge mitte skizze desselben mit eingezeichneter fester gewichtsschicht unter verwendung der definier ten funktionsbeschreibenden designs neurone unten ohne eingezeichnete feste gewichtsschicht mit benennung der einzelnen neuronen nach unserer konvention wir werden die feste gewichtschicht weiteren verlauf der arbeit nicht mehr betrachten kriesel ein kleiner uberblick uber neuronale netze epsilon figure architecture perceptron one layer variable connections different views solid drawn weight layer two illustrations bottom trained left side example scanning information eye right side upper part drawing example indicated fixed weight layer using defined designs functional descriptions neurons right side lower part without indicated fixed weight layer name neuron corresponding convention fixed weight layer longer taken account course work whether method reasonable another matter course easiest way achieve boolean logic want illustrate perceptrons used simple logical components theoretically speaking boolean function realized means perceptrons connected series interconnected sophisticated way see possible without connecting serially providing definition perceptron want define types neurons used chapter definition input neuron input neuron identity neuron exactly forwards information received thus represents identity function indicated symbol therefore input neuron represented symbol gfed abc definition information processing neuron information processing neu rons somehow process input information represent identity func tion binary neuron sums inputs using weighted sum propagation function want illustrate sign activation function neuron binary threshold function illustrated leads complete depiction information processing neurons namely wvut pqrs neurons use weighted sum propagation function activation functions hyperbolic tangent fermi function separately defined activation function act similarly represented wvut pqrs tanh wvut pqrs fermi onml hijk act neurons also referred fermi neurons tanh neuron know components perceptron able define definition perceptron perceptron fig feedforward network containing retina used data acquisition fixed weighted connections first neuron layer input layer fixed weight layer followed least one trainable weight layer one neuron layer completely linked following layer first layer perceptron consists input neurons defined feedforward network often contains shortcuts exactly correspond original description therefore included definition see retina included lower part fig matter fact first neuron layer often understood simplified sufficient method input layer layer forwards input values retina static weights behind longer mentioned displayed since process information case depiction perceptron starts input neurons may confuse readers claim definition perceptron define perceptron following section therefore suggest keeping definition back mind take granted course work snipe methods setsettingstopologyfeedforward variation withshortcuts neuralnetworkdescriptor instance apply settings descriptor appropriate feedforward networks feedforward networks shortcuts respective kinds connections allowed others fastprop activated 
[perceptron, backpropagation, variants, singlelayer, perceptron, provides, one, trainable, weight, layer] connections trainable weights input layer output neuron returns information whether pattern entered input neurons recognized thus singlelayer perception abbreviated slp one level trainable weights fig definition singlelayer perceptron singlelayer perceptron slp perceptron one layer variable weights one layer output neurons technical view slp shown fig certainly existence several output neurons considerably change concept perceptron fig perceptron several output neurons also regarded several different perceptrons input boolean functions shown fig trivial examples easily composed want know train singlelayer perceptron therefore first take look perceptron learning algorithm look delta rule 
[perceptron, backpropagation, variants, singlelayer, perceptron, provides, one, trainable, weight, layer, perceptron, learning, algorithm, convergence, theorem] original perceptron learning algorithm binary neuron activation function described alg proven algorithm converges finite time finite time perceptron learn anything represent perceptron convergence theorem please get hopes soon perceptron capable represent explored later exploration linear separability problems cover fact least singlelayer perceptron unfortunately cannot represent lot problems gfed abc bias bias gfed abc gfed abc figure singlelayer perceptron two input neurons one output neuron network returns output means arrow leaving network trainable layer weights situated center labeled reminder bias neuron included although weight bias normal weight also treated like represented dotted line significantly increases clarity larger networks future bias neuron longer included gfed abc gfed abc gfed abc gfed abc vvnnnn nnnn nnnn nnnn gfed abc ttiiiii iiiii iiiii iiiii iiiii wwnnnn nnnn nnnn nnnn gfed abc gfed abc gfed abc figure singlelayer perceptron several output neurons gfed abc gfed abc gfed abc gfed abc gfed abc gfed abc figure two singlelayer perceptrons boolean functions upper singlelayer perceptron realizes lower one realizes activation function information processing neuron binary threshold function available threshold values written neurons error large input network calculate output set training patterns output neurons output okay correction weights else input neurons increase weight towards end end input neurons decrease weight towards end end end end end algorithm perceptron learning algorithm perceptron learning algorithm reduces weights output neurons return instead inverse case increases weights 
[perceptron, backpropagation, variants, singlelayer, perceptron, provides, one, trainable, weight, layer, delta, rule, gradient, based, learning, strategy, slps] following deviate binary threshold value activation function least backpropagation error need see differen tiable even semi linear activation function following delta rule like backpropagation derived always necessary useful fact however also pointed appropriate part work compared aforementioned perceptron learning algorithm delta rule advantage suitable non binary activation functions far away learning target automatically learn faster suppose singlelayer perceptron randomly set weights want teach function means training samples set training samples called contains already defined pairs training samples associated teaching input also want remind input vector output vector neural network output neurons referred input output neuron additionally defined error vector represents difference certain training sample furthermore let set output neurons set input neurons another naming convention shall example output teaching input additional index may set order indicate values pattern specific sometimes considerably enhance clarity learning target certainly training samples output network approximately desired output formally true means first understand total error err function weights total error increases decreases depending change weights figure exemplary error surface neural network two trainable connections und generally neural networks two connections would made illustration complex time error surface craggy complicates search minimum definition error function error function err regards set weights vector maps values onto normalized output error normalized otherwise errors mapped onto one single perform gradient descent obvious specific error function analogously generated single pattern already shown section gradient descent procedures calculate gradient arbitrary finite dimensional function error function err move direction gradient minimum reached err defined set weights regard vector try decrease minimize error simply tweaking weights thus one receives information change weights change weights referred calculating gradient err error function err err due relation proportionality constant equality holds soon get another meaning real practical use beyond mere meaning proportionality constant ask reader patient err following tradition literature previously defined weight matrix aware conflict bother simplify analysis rewrite gradient error function according weights usual partial derivative according single weight variable weights exists hidden output layer thus tweak every single weight observe error function changes derive error function according weight obtain value change weight err following question arises error function defined exactly good many results far away desired ones error function provide large values hand similarly bad many results close desired ones exists extremely far outlying result squared distance output vector teaching input appears adequate needs provides error err specific training sample output output neurons err thus calculate squared difference components vectors given pattern sum squares summation specific errors err patterns yields definition error err therefore definition error function err err err sum   sum observant reader certainly wonder factor equation suddenly came root equation formula looks similar euclidean distance facts result simple pragmatics intention minimize error root function decreases argument simply omit reasons calculation implementation efforts since need minimization similarly matter term minimized divided therefore allowed multiply done cancels course calculation want continue deriving delta rule linear activation functions already discussed tweak individual weights bit see error err changing corresponds derivative error function err according weight derivative corresponds sum derivatives specific errors err according weight since total error err results sum specific errors err err want think question neural network processes data basically data transferred function result function sent another one ignore output function path neuron outputs neurons entered neuron initially propagation function weighted sum network input going received sent activation function neuron receive output neuron time component output vector net act act net see output results many nested functions act net act clear could break output single input neurons unnecessary since process information slp thus want calculate derivatives equation due nested functions apply chain rule factorize derivative err equation err err let take look first multiplicative factor equation represents derivative specific error err according output change error err output examination err equation clearly shows change exactly difference teaching input output remember since output neuron closer output teaching input smaller specific error thus replace one difference also called reason name delta rule err second multiplicative factor equation following one derivative output specific pattern neuron according weight change weight changed due requirement beginning derivation linear activation function act therefore well look change network input changing err resulting derivative simplified function derived consists many summands sum mand contains variable according derive thus therefore err insert equation results modification rule weight however beginning derivation intended offline rule means question add errors patterns learn patterns represented although approach mathematically correct implementation far time consuming see later chapter partially needs lot compuational effort training online learning version delta rule simply omits summation learning realized immediately presentation pattern also simplifies notation longer necessarily related pattern version delta rule shall used following definition definition delta rule determine analogously aforementioned derivation function hebbian theory equation provides output predecessor neuron function difference desired activation actual activation receive delta rule also known widrow hoff rule use desired output instead activation teaching input therefore output function output neurons represent identity obtain corresponds difference case delta rule change weights output neuron proportional difference current activation output corresponding teaching input want refer factor also referred delta apparently delta rule applies slps since formula always related teaching input teaching input inner processing layers neurons output table definition logical xor input values shown left output values right gfed abc gfed abc xor figure sketch singlelayer perceptron shall represent xor function impossible 
[perceptron, backpropagation, variants, slp, capable, representing, linearly, separable, data] let xor function expects two binary inputs generates binary output precise definition see table let try represent xor function means slp two input neurons one output neuron fig use weighted sum propagation function binary activation function threshold value identity output function depending output value following holds net figure linear separation inputs input neurons dimensional straight line show corners belonging sets xor function separated assume positive weight inequality equivalent constant threshold value right part inequation straight line coordinate system defined possible outputs und input neurons fig required inequation positive output neuron fires input combinations lying generated straight line negative would fire input combinations lying straight line note four corners unit square possible inputs xor function knows binary inputs order solve xor problem turn move straight line input set separated input set obviously impossible figure linear separation inputs input neurons dimensional plane generally input parameters many input neurons represented dimensional cube separated slp dimensional hyperplane fig sets separated hyperplane linearly separable classified slp unfortunately seems percentage linearly separable problems rapidly decreases increasing see table limits func tionality slp additionally tests linear separability difficult thus difficult tasks inputs need something powerful slp xor problem one tasks since perceptron supposed represent xor function already needs hidden layer fig 
[perceptron, backpropagation, variants, multilayer, perceptron, contains, trainable, weight, layers] perceptron two trainable weight layers called multilayer perceptron mlp powerful slp know singlelayer perceptron divide number binary functions lin separable ones share table number functions concerning binary inputs number proportion functions thereof linearly separated accordance gfed abc gfed abc gfed abc gfed abc xor figure neural network realizing xor function threshold values far existing located within neurons input space means hyperplane two dimensional input space means straight line two stage perceptron two trainable weight layers three neuron layers classify convex polygons processing straight lines form recognize patterns lying straight line straight line straight line thus metaphorically speaking took slp several output neurons attached another slp upper part fig multilayer perceptron represents universal function approximator proven theorem cybenko another trainable weight layer proceeds analogously convex polygons added subtracted somehow processed operations lower part fig generally mathematically proven even multilayer perceptron one layer hidden neurons arbitrarily precisely approximate functions finitely many discontinuities well first derivatives unfortunately proof constructive therefore left find correct number neurons weights following want use widespread abbreviated form different multilayer perceptrons denote two stage perceptron neurons input layer neurons hidden layer neurons output layer mlp definition multilayer perceptron perceptrons one layer variably weighted connections referred multilayer perceptrons mlp layer stage perceptron thereby exactly variable weight layers neuron layers retina disregarded neuron layer input layer since three stage perceptrons classify sets form combining sepa rating arbitrarily many convex polygons another step advantageous respect function representations cautious reading literature many different definitions counted layer sources count neuron layers count weight layers sources include retina trainable weight layers exclude reason output neuron layer work chose definition provides opinion information learning capabilities use cosistently remember stage perceptron exactly trainable weight layers find summary perceptrons classify types sets table want face challenge training perceptrons one weight layer gfed abc gfed abc ttjjjjj jjjjj jjjjj jjjjj jjjjj gfed abc gfed abc gfed abc wwoooo oooo oooo oooo gfed abc gfed abc gfed abc gfed abc gfed abc gfed abc gfed abc gfed abc wwnnnn nnnn nnnn nnnn gfed abc gfed abc figure know slp represents straight line trainable weight layers several straight lines combined form convex polygons using trainable weight layers several polygons formed arbitrary sets classifiable sets hyperplane convex polygon set set well advantage table representation perceptron classify types sets number trainable weight layers 
[perceptron, backpropagation, variants, backpropagation, error, generalizes, delta, rule, allow, mlp, training] next want derive explain backpropagation error learning rule breviated backpropagation backprop used train multi stage perceptrons semi linear activation functions binary threshold functions non differentiable functions longer supported matter seen fermi function hyperbolic tangent arbitrarily approx imate binary threshold function means temperature parameter large extent follow derivation according want point procedure previously published paul werbos backpropagation gradient descent procedure including strengths weak nesses gradient descent error function err receiving weights arguments fig assigning output error dimensional err point small error even point smallest error sought means gradient descent thus analogy delta rule back propagation trains weights neural network exactly delta rule variable neuron expanded one trainable weight layer several ones backpropagation semilinear functions monotonous differentiable generally linear amp amp pppp pppp wwpppp ppp onml hijk act xxrrr rrr rrr rrr rrr figure illustration position neuron within neural network lying layer preceding layer subsequent layer 
[perceptron, backpropagation, variants, backpropagation, error, generalizes, delta, rule, allow, mlp, training, derivation, similar, one, delta, rule, generalized, delta] let define advance network input individual neurons results weighted sum furthermore derivation delta rule let net etc defined already familiar net etc input pattern used training let output function identity thus act net holds neuron since generalization delta rule use formula framework delta rule equation already indicated generalize variable every neuron first neuron want calculate obvious select arbitrary inner neuron set predecessor neurons well set successor neurons also inner neurons see fig therefore irrelevant whether predecessor neurons already input neurons perform derivation delta rule split functions means chain rule discuss derivation great detail principal similar delta rule differences already mentioned generalized initially derive error function err according weight err err net net first factor equation deal later text numerator second factor equation includes network input weighted sum included numerator immediately derive summands sum drop apart summand containing summand referred calculate derivative output neuron becomes net promised discuss equation split according chain rule err net err net derivation output according network input second factor equation clearly equals derivation activation function according network input net act net net act net consider important passage analogously derive first factor equation therefore point derivation error function according output inner neuron layer depends vector network inputs next following layer reflected equation err err net net according definition multi dimensional chain rule immediately obtain equation err err net net sum equation contains two factors want discuss factors added subsequent layer simply calculate second factor following equation net applies first factor according definition err net insert err find graphic version generalization including splittings fig reader might already noticed intermediate results shown frames exactly intermediate results highlighted way factor change weight aforementioned equations combined highlighted intermediate results outcome wanted change weight act net course case inner neuron otherweise would subsequent layer err net net err act net err net net figure graphical representation equations equal signs chain rule splittings arrows framework backpropagation derivation leaves tree reflect final results generalization framed derivation case output neuron already discussed derivation delta rule result generalization delta rule called backpropagation error act net outside act net inside contrast delta rule treated differently depending whether output inner hidden neuron output neuron act net thus training pattern weight changed proportionally according learning rate output predecessor neuron gradient activation function position network input successor neuron act net difference teaching input output successor neuron case backpropagation working two neuron layers output layer successor neuron preceding layer predecessor neuron inner hidden neuron act net holds want explicitly mention backpropagation working three layers neuron predecessor connection changed weight neuron successor connection changed neurons lying layer following successor neuron thus according training pattern weight proportionally changed according learning rate output predecessor neuron gradient activation function position network input successor neuron act net well difference according weighted sum changes weight neurons following definition backpropagation summarize formulas receive following final formula back propagation identifiers ommited reasons clarity act net outside act net inside snipe online variant backpropagation implemented method trainbackpropagationoferror within class neuralnetwork obvious backpropagation initially processes last weight layer directly means teaching input works backwards layer layer con sidering preceding change weights thus teaching input leaves traces weight layers describe first delta rule second part backpropaga tion generalized delta rule layers one may meet requirements matter research first part obvious soon see framework mathematical gimmick decades development time work lie first second recursive part like many groundbreaking inventions development recognized plausible invention 
[perceptron, backpropagation, variants, backpropagation, error, generalizes, delta, rule, allow, mlp, training, heading, back, boiling, backpropagation, delta, rule] explained delta rule special case backpropagation one stage perceptrons linear activation functions want briefly explain circum stance develop delta rule backpropagation order augment understanding rules seen backpropagation defined act net outside act net inside since use one stage perceptrons second part backpropagation light colored omitted without substitution result act net furthermore want use linear activation functions act light colored constant generally known constants combined therefore directly merge constant derivative act constant least one lerning cycle learning rate also light colored thus result exactly corresponds delta rule definition 
[perceptron, backpropagation, variants, backpropagation, error, generalizes, delta, rule, allow, mlp, training, selection, learning, rate, heavy, influence, learning, process] meantime often seen change weight case propor tional learning rate thus selection crucial behaviour backpropagation learning procedures general definition learning rate speed accuracy learning procedure always controlled always proportional learning rate written value chosen large jumps error surface also large example narrow valleys could simply jumped additionally movements across error surface would uncontrolled thus small desired input however cost huge often unacceptable amount time experience shows good learning rate values range selection significantly depends problem network training data barely possible give practical advise instance popular start relatively large slowly decrease simpler problems often kept constant variation learning rate time training another stylistic device variable learning rate beginning large learning rate leads good results later results inaccurate learning smaller learning rate time consuming result precise thus learning process learning rate needs decreased one order magnitude repeatedly common error also seems neat solution first glance continually decrease learning rate quickly happens descent learning rate larger ascent hill error function climbing result simply get stuck ascent solution rather reduce learning rate gradually mentioned different layers different learning rates farer move away output layer learning process slower backpropagation learning thus good idea select larger learning rate weight layers close input layer weight layers close output layer 
[perceptron, backpropagation, variants, resilient, backpropagation, extension, backpropagation, error] raised two backpropagation specific properties occasionally problem addition already caused gradient descent one hand users backpropagation choose bad learning rate hand weights output layer slower backpropa gation learns reason martin riedmiller enhanced backpropagation called version resilient backpropagation short rprop want compare backpropagation rprop without explicitly declaring one version superior actually dealing formulas let informally compare two primary ideas behind rprop consequences already familiar backpropagation learning rates backpropagation uses default learning rate selected user applies entire network remains static manually changed already explored disadvantages approach rprop pursues completely different approach global learning rate first weight learning rate second learning rates chosen user automatically set rprop third weight changes static adapted time step rprop account temporal change correctly call enables focused learning also problem increasingly slowed learning throughout layers solved elegant way weight change using backpropagation weights changed proportionally gradient error function first glance really intuitive however incorporate every jagged feature error surface weight changes least questionable whether always useful rprop takes ways well amount weight change simply directly corresponds automatically adjusted learning rate thus change weight proportional gradient influenced sign gradient still know exactly adapted run time let anticipate resulting process looks considerably less rugged error function contrast backprop weight update step replaced additional step adjustment learning rate added exactly ideas implemented 
[perceptron, backpropagation, variants, resilient, backpropagation, extension, backpropagation, error, weight, changes, proportional, gradient] let first consider change weight already noticed weight specific learning rates directly serve absolute values changes respective weights remains question sign comes point gradient comes play derivation backpropagation derive error function err individual weights obtain gradi ents err big difference rather multiplicatively incorporating absolute value gradient weight change consider sign gradient gradient hence longer determines strength direction weight change sign gradient err positive must decrease weight weight reduced sign gradient negative weight needs increased added gradient exactly nothing happens let create formula colloquial description corresponding terms affixed show everything happens time step might decrease clarity first glance nevertheless important soon look another formula operates different time steps instead shorten gradient err definition weight change rprop otherwise know weights changed remains question learning rates adjusted finally understood overall system deal remaining details like initialization specific constants 
[perceptron, backpropagation, variants, resilient, backpropagation, extension, backpropagation, error, many, dynamically, adjusted, learning, rates, instead, one, static] adjust learning rate consider associated gradients two time steps gradient passed current one sign gradient matters must ask happen sign two time steps stay flip sign changes skipped local minimum gra dient hence last update large reduced compared previous one say search needs accurate mathematical terms obtain new multiplying old constant case know last time step something went wrong hence additionally reset weight update weight time step applied shown following formula however sign remains one perform careful increase get past shallow areas error function obtain new multiplying old constant greater definition adaptation learning rates rprop otherwise caution also implies rprop exclusively designed offline gradients certain continuity learning process slows lowest rates remains learning online one changes loosely speaking error function new epoch since based one training pattern may often well applicable backpropagation often even faster offline version used frequently lacks however clear mathematical motivation exactly need 
[perceptron, backpropagation, variants, resilient, backpropagation, extension, backpropagation, error, still, missing, details, use, rprop, practice] minor issues remain unanswered namely large much learning rates reinforced weak ened choose weight specific learning rates initialized upper lower bounds min max set answer questions quick motivation initial value learning rates somewhere order initialization weights proven good choice authors rprop paper explain obvious way value long positive without exorbitantly high absolute value need dealt critically quickly overridden automatic adaptation anyway equally uncritical max recommend without mathematical justification value used throughout literature one set parameter lower values order allow cautious updates small update steps allowed case set min left parameters let start value used skipped minimum know exactly lies skipped track analogous procedure binary search target object often skipped well assume middle skipped track need halve learning rate canonical choice selected value used learning rates shall increased caution cannot generalize principle binary search simply use value otherwise learning rate update end consisting almost exclusively changes direction independent particular problems value proven protipp since changed multiplication would rather suboptimal initialization promising slight changes value significantly affected rate convergence fact allowed setting value constant well advancing computational capabilities computers one observe widespread distribution networks consist big number layers deep networks networks crucial prefer rprop original backpropagation backprop already indicated learns slowly weights wich far output layer problems smaller number layers would recommend testing widespread backpropagation offline online learning less common rprop equivalently snipe snipe resilient backpropagation supported via method trainresilientbackpropagation class neuralnetwork furthermore also use additional improvement resilient propagation however dealt work getters setters different parameters rprop 
[perceptron, backpropagation, variants, backpropagation, often, extended, altered, besides, rprop] backpropagation often extended many extensions simply implemented optional features backpropagation order larger scope testing following want briefly describe 
[perceptron, backpropagation, variants, backpropagation, often, extended, altered, besides, rprop, adding, momentum, learning] let assume descent steep slope skis prevents immediately stopping edge slope plateau exactly momentum backpropagation momentum term responsible fact kind moment inertia momentum added every step size fig always adding fraction previous change every new change weight previous course notation used better understanding generally already defined concept time referring current cycle previous cycle identified continued successively come formal definition momentum term figure want execute gradient descent like skier crossing slope would hardly stop immediately edge plateau definition momentum term variation backpropagation means momentum term defined follows accelerate plateaus avoiding quasi standstill plateaus slow craggy surfaces preventing oscillations moreover effect inertia varied via prefactor common values und additionally momen tum enables positive effect skier swings back forth several times minimum finally lands minimum despite nice one dimensional pearance otherwise rare error leaving good minima unfortunately occurs frequently momentum term means optimal solution accustomed condition 
[perceptron, backpropagation, variants, backpropagation, often, extended, altered, besides, rprop, flat, spot, elimination, prevents, neurons, getting, stuck] must pointed hyperbolic tangent well fermi function derivative outside close proximity nearly results fact becomes difficult move neurons away limits activation flat spots could extremely extend learning time problem dealt modifying derivative example adding constant called flat spot elimination colloquial fudging interesting observation success also achieved using derivatives defined constants nice example making use effect fast hyperbolic tangent approximation anguita introduced section outer regions well approximated accelerated derivative makes use small constant 
[perceptron, backpropagation, variants, backpropagation, often, extended, altered, besides, rprop, second, derivative, used] according david parker second order backpropagation also usese second gradient second multi dimensional derivative error function obtain precise estimates correct even higher derivatives rarely improve estimations thus less training cycles needed require much computational effort general use derivatives hessian matrices since functions multidimensional higher order methods expected procedures reduce number learning epochs significantly increase computational effort individual epochs end procedures often need learning time backpropagation quickpropagation learning procedure uses second derivative error propagation locally understands error function parabola analytically determine vertex lowest point said parabola directly jump point thus learning procedure second order procedure course work error surfaces cannot locally approximated parabola certainly always possible directly say whether case 
[perceptron, backpropagation, variants, backpropagation, often, extended, altered, besides, rprop, weight, decay, punishment, large, weights] weight decay according paul werbos modification extends error term punishing large weights error weight decay err increase proportionally actual error also proportionally square weights result network keeping weights small learning err err punishment approach inspired nature synaptic weights cannot become infinitely strong well additionally due small weights error function often shows weaker fluctuations allowing easier controlled learning prefactor resulted simple pragmatics factor controls strength punishment values often used 
[perceptron, backpropagation, variants, backpropagation, often, extended, altered, besides, rprop, cutting, networks, down, pruning, optimal, brain, damage] executed weight decay long enough notice neuron input layer successor weights close remove neuron hence losing neuron weights thereby reduce possibility network memorize procedure called pruning method detect delete unnecessary weights neurons referred optimal brain damage want describe briefly mean error per output neuron composed two competing terms one term usual considers difference output teaching input one tries press weight towards weight strongly needed minimize error first term win case second term win neurons zero weights pruned end many variations backprop whole books subject since aim offer overview neural networks want mention variations motivation read extensions obvious cannot applied feedfor ward networks backpropagation learning procedures gotten know backpropagation feedforward topology learn build neural network course impossible fully communicate experience framework work obtain least knowledge advise deal exemplary problems 
[perceptron, backpropagation, variants, getting, started, initial, configuration, multilayer, perceptron] discussed backpropagation error learning procedure knowing train existing network would useful consider implement network 
[perceptron, backpropagation, variants, getting, started, initial, configuration, multilayer, perceptron, number, layers, two, three, may, often, job, also, used] let begin trivial circumstance network one layer input neurons one layer output neurons results least two layers additionally need already learned examination linear separability least one hidden layer neurons problem linearly separable seen likely possible already mentioned mathematically prove mlp one hidden neuron layer already capable approximating arbitrary functions accuracy necessary discuss representability problem means perceptron also learnability representability means perceptron principle realize mapping learnability means also able teach respect experience shows two hidden neuron layers three trainable weight layers useful solve problem since many problems represented hidden layer difficult learn one keep mind additional layer generates additional sub minima error function get stuck things considered promising way try one hidden layer first fails retry two layers fails one consider layers however given increasing calculation power current computers deep networks lot layers also used success note indicated number neurons hidden layer mentioned hypo thetical possibility 
[perceptron, backpropagation, variants, getting, started, initial, configuration, multilayer, perceptron, number, neurons, tested] number neurons apart input output layer number input output neurons already defined problem statement principally corresponds number free parameters problem represented since already discussed network capacity respect memorizing imprecise problem representation clear goal free parameters possible many necessary also know standard solution question many neurons used thus useful approach initially train neurons repeatedly train new networks neurons result significantly improves particularly generalization performance affected bottom approach 
[perceptron, backpropagation, variants, getting, started, initial, configuration, multilayer, perceptron, selecting, activation, function] another important parameter way information processing neural network selection activation function activation function input neurons fixed identity function since process information first question asked whether actually want use activation function hidden layer ouput layer one prevents choosing different functions generally activation function hidden neurons well output neurons respectively tasks function approximation found reasonable use perbolic tangent left part fig activation function hidden neurons linear activation function used output latter absolutely necessary generate limited output intervall contrary input layer uses linear activation functions well output layer still processes information threshold values however linear activation func tions output also cause huge learning steps jumping good minima error surface avoided setting learning rate small values output layer unlimited output interval essential pattern recognition tasks hyperbolic tangent used case output interval bit larger unlike generally pattern recognition understood special case function approximation discrete output possibilities tanh hyperbolic tangent fermi function temperature parameter figure reminder illustration hyperbolic tangent left fermi function right fermi function expanded temperature parameter original fermi function thereby represented dark colors temperature parameter modified fermi functions ordered ascending steepness hyperbolic tangent fermi function right part fig difficult learn something far threshold value result close however lot freedom given selecting activation function generally disadvantage sigmoid functions fact hardly learn something values far thei threshold value unless network modified 
[perceptron, backpropagation, variants, getting, started, initial, configuration, multilayer, perceptron, weights, initialized, small, randomly, chosen, values] initialization weights trivial one might think simply initialized change weights initialized value change equally training simple solution problem called symmetry breaking initialization weights small random values range random values could interval including values close random initialization nice side effect chances average network inputs close value hits activation functions region greatest derivative allowing strong learning impulses right start learning snipe snipe weights initialized randomly synapse initialization wanted maximum absolute weight value synapse initialized random set neuralnetworkdescriptor using method setsynapseinitialrange 
[perceptron, backpropagation, variants, , encoding, problem, related, problems] encoding problem classic among multilayer perceptron test training problems mlp input layer eight neurons output layer eight neurons one hidden layer three neurons thus network represents function training task input value neuron lead output value neuron one neuron activated results training samples analysis trained network see network hidden neurons represents kind binary encoding mapping possible assumed training time epochs thus network machine input first encoded afterwards decoded analogously train encoding problem possible improve efficiency procedure could example encoding network yes even possible since network depend binary encodings thus network sufficient problem encoding network far difficult understand fig training networks requires lot time snipe static method getencodersamplelesson class trainingsamplelesson allows creating simple training sample lessons arbitrary dimensionality encoder problems like network however work since possibility output one neuron compensated another one essential one hidden neuron certainly compensatory neuron 
[perceptron, backpropagation, variants, exercises] exercise fig shows small network boolean functions write tables computational parameters neural networks network input activation etc perform calculations four possible inputs networks write values variables input xor network fig exercise figure illustration functionality network encoding marked points rep resent vectors inner neuron activation associated samples see possible find inner activation formations point separated rest points straight line illustration shows exemplary separation one point list boolean functions linearly separable characterize exactly list linearly separable characterize exactly exercise simple network shall trained one single pattern means backpropagation error verify error err err converges value error curve look like let pattern defined randomly initalize weights interval exercise one stage perceptron two input neurons bias neuron binary threshold function activation function divides two dimensional space two regions means straight line analytically calculate set weight values perceptron following set patterns form correctly classified exercise calculate comprehensible way one vector changes weight means backpropagation error procedure let mlp bias neuron given let pattern defined weights target initial value weights weights initial value conspicuous changes 
[radial, basis, functions] rbf networks approximate functions stretching compressing gaussian bells summing spatially shifted description functions learning process comparison multilayer perceptrons according poggio girosi radial basis function networks rbf net works paradigm neural networks developed considerably later perceptrons like perceptrons rbf networks built layers case exactly three layers one single layer hidden neurons like perceptrons networks feedforward structure layers com pletely linked input layer participate information process ing rbf networks like mlps universal function approximators despite things common difference rbf networks perceptrons difference lies information processing compu tational rules within neurons outside input layer moment define far unknown type neurons 
[radial, basis, functions, components, structure, rbf, network] initially want discuss colloquially define concepts concerning rbf networks output neurons rbf network output neurons contain identity activation function one weighted sum propagation function thus little adding input values returning sum hidden neurons also called rbf neurons well layer located referred rbf layer propagation function hidden neuron calculates norm represents distance input network called position neuron center inserted radial activation function calculates outputs activation neuron definition rbf input neuron definition representation identical definition input neuron definition center rbf neuron center rbf neuron point input space rbf neuron located general closer input vector center vector rbf neuron higher activation definition rbf neuron called rbf neurons propagation function prop determines distance center neuron input vector distance represents network input network input sent radial basis function act returns activation output neuron rbf neurons represented symbol wvut pqrs gauß definition rbf output neuron rbf output neurons use weighted sum propagation function prop identity activation function act represented symbol onml hijk definition rbf network rbf network exactly three layers following order input layer consisting input neurons hidden layer also called rbf layer consisting rbf neurons output layer consisting rbf output neurons layer completely linked following one shortcuts exist fig feedforward topology connections input layer rbf layer unweighted transmit input connections rbf layer output layer weighted original definition rbf network referred output neuron analogy perceptrons apparent definition generalized bias neuron used rbf networks set input neurons shall represented set hidden neurons set output neurons therefore inner neurons called radial basis neurons defini tion follows directly input vectors distance center neuron also produce output value fig gfed abc yyy yyy yyy gfed abc yyy yyy yyy vvllll llll llll llll llll sshhhhhh hhhhhh hhhhhh hhhhhh hhhhhh wvut pqrs gauß wvut pqrs gauß wvut pqrs gauß wvut pqrs gauß vvmmmm mmmm mmmm mmmm mmmm wvut pqrs gauß tthhhhh hhhhh hhhhh hhhhh hhhhh hhhhh vvmmmm mmmm mmmm mmmm mmmm onml hijk onml hijk onml hijk figure exemplary rbf network two input neurons five hidden neurons three output neurons connections hidden neurons weighted transmit input right illustration find names neurons coincide names mlp neurons input neurons called hidden neurons called output neurons called associated sets referred figure let center rbf neuron activation function act radially symmetric around gaussian gaussian figure two individual one two dimensional gaussian bells cases holds centers gaussian bells lie coordinate origin distance center simply calculated according pythagorean theorem 
[radial, basis, functions, information, processing, rbf, network] question realized network purpose let rbf network top bottom rbf network receives input means unweighted connections input vector sent norm result scalar scalar way positive due norm processed radial basis function example gaussian bell fig output values different neurons rbf layer different gaussian bells added within third layer basically relation whole input space gaussian bells added suppose second third fourth rbf neuron therefore four differently located centers neurons measures another distance input center facto provides different values even gaussian bell since values finally simply accumulated output layer one easily see surface shaped dragging compressing removing gaussian bells subsequently accumulating parameters superposition gaussian bells weights connections rbf layer output layer figure four different gaussian bells one dimensional space generated means rbf neurons added output neuron rbf network gaussian bells different heights widths positions centers located widths see two dimensional example fig furthermore network architecture offers possibility freely define train height width gaussian bells due network paradigm becomes even versatile get know methods approches later 
[radial, basis, functions, information, processing, rbf, network, information, processing, rbf, neurons] rbf neurons process information using norms radial basis functions first let take example simple rbf network apparent receive one dimensional output represented function fig additionally network includes centers four inner neurons therefore gaussian bells finally added within output neuron network also possesses four values influence width gaussian bells contrary height gaussian bell influenced subsequent weights since individual output values bells multiplied weights gaussian gaussian gaussian gaussian wvut pqrs gauß wvut pqrs gauß wvut pqrs gauß wvut pqrs gauß vvmmmm mmmm mmmm mmmm mmm onml hijk sum gaussians figure four different gaussian bells two dimensional space generated means rbf neurons added output neuron rbf network applies distance heights widths centers since use norm calculate distance input vector center neuron different choices often euclidian norm chosen calculate distance remember input vector referred index runs input neurons thereby input vector components neuron center components see euclidean distance generates squared differences vector components adds extracts root sum two dimensional space corresponds pythagorean theorem definition norm directly follows distance positive strictly speaking hence use positive part activation function way activation functions gaussian bell possible normally functions monotonically decreasing interval chosen know distance input vector center rbf neuron distance passed activation function use already mentioned gaussian bell act obvious center width seen part activation function act hence activation functions referred act simultaneously one solution would number activation functions like act act act set hidden neurons result explanation would confusing simply use name act activation functions regard variables defined individual neurons directly included activation function reader certainly notice literature gaussian bell often malized multiplicative factor however avoid factor multiplying anyway subsequent weights consecutive multiplications first normalization factor connections weights would yield different factors need factor especially purpose integral gaussian bell must always therefore simply leave 
[radial, basis, functions, information, processing, rbf, network, analytical, thoughts, prior, training] output rbf output neuron results combining functions rbf neuron act suppose similar multilayer perceptron set contains training samples obtain functions form act one function training sample course effort aiming letting output training patterns converge corresponding teaching input weights simply computed solution system equations thus equations let assume widths centers training samples including teaching input given looking weights weights one output neuron thus problem seen system equations since thing want change moment weights demands distinction cases concerning number training samples number rbf neurons number rbf neurons equals number patterns equation reduced matrix multiplication vector teaching inputs training samples matrix outputs rbf neurons samples remember matrix squared therefore attempt invert vector desired weights unit matrix size mathematically speaking simply calculate weights case exactly one rbf neuron available per training sample means network exactly meets existing nodes calcu lated weights performs precise interpolation calculate equation certainly need rbf network therefore proceed next case exact interpolation must mistaken memorizing ability mentioned mlps first talking training rbf networks moment second could advantageous might fact intended network exactly interpolates nodes system equations determined rbf neurons training samples certainly case normally occur often case huge variety solutions need detail select one set weights many obviously possible ones interesting discussion case signifi cantly training samples rbf neurons means thus want use generalization capability neural network training samples rbf neurons cannot assume every training sample exactly hit cannot exactly hit points therefore cannot interpolate aforementioned ideal case must try find function approximates training set closely possible mlp try reduce sum squared error minimum continue calculation case solve system equations find solution matrix multiplication problem time cannot invert matrix square matrix true use moore penrose pseudo inverse defined although moore penrose pseudo inverse inverse matrix used similarly case get equations similar case another reason use moore penrose pseudo inverse fact minimizes squared error goal estimate vector equation corresponds gauss markov model known statistics used minimize squared error aforementioned equations following ones please mistake transpose matrix vector teaching inputs generalization several outputs trivial quite computationally expensive found mathematically exact way directly calculate weights happen several output neurons usual set output neurons case already indicated change much additional output neurons set weights change rbf layer thus rbf network easy given realize lot output neurons since calculate individual vector weights every new output neuron whereas matrix generally requires lot computational effort always stays quite inexpensive least concerning computational complexity add output neurons particularly true invertible want detail reasons circumstances applications easily found literature linear algebra computational effort accuracy realistic problems normally applies considerably training samples rbf neurons without difficulty use training samples like theoretically could find terms mathemati cally correct solution blackboard long time calculations often seem imprecise time consuming matrix inversions require lot computational effort furthermore moore penrose pseudo inverse spite numeric stability guarantee output vector corresponds teaching vector extensive computations prone many inaccuracies even though calculation mathematically correct computers provide nonetheless good approximations pseudo inverse matrices means also get approximations correct weights maybe lot accumulated numerical errors therefore approximation maybe rough even unrecognizable desired output enough computing power analytically determine weight vector use nevertheless initial value learning process leads real training methods otherwise would boring 
[radial, basis, functions, combinations, equation, system, gradient, strategies, useful, training] analogous mlp perform gradient descent find suitable weights means already well known delta rule backpropagation unnecessary since train one single weight layer requires less computing time know delta rule insert follows act explicitly want mention popular divide training two phases analytically computing set weights refining training delta rule still question whether learn offline online answer similar answer multilayer perceptron initially one often trains online faster movement across error surface approximated solution errors accumulated precise approximation one trains offline third learning phase however similar mlps successful using many methods already indicated rbf network weights hidden output layer optimized let take look possibility vary 
[radial, basis, functions, combinations, equation, system, gradient, strategies, useful, training, always, trivial, determine, centers, widths, rbf, neurons] obvious approximation accuracy rbf networks increased adapting widths positions gaussian bells input space problem needs approximated several methods deal centers widths gaussian bells fixed selection centers widths selected fixed manner regard less training samples assumed conditional fixed selection centers widths selected fixedly previous knowledge functions approximated comply adaptive learning process definitely elegant variant cer tainly challenging one realization approach discussed chapter found connection another network topology section fixed selection case goal cover input space evenly possible widths distance centers selected gaussian bells overlap approx one third fig closer bells set precise time consuming whole thing becomes apparent gaussian bell mathematically infinitely wide therefore ask reader apologize sloppy formulation figure example even coverage two dimensional input space applying radial basis functions may seem inelegant field function approximation cannot avoid even coverage useless function approximated precisely represented positions positions return value however high input dimension requires great many rbf neurons creases computational effort exponentially dimension responsible fact six ten dimensional problems rbf networks already called high dimensional mlp example cause problems conditional fixed selection suppose training samples evenly distributed across input space seems obvious arrange centers sigmas rbf neurons means pattern distribution training patterns analyzed statistical techniques cluster analysis determined whether sta tistical factors according distribute centers sigmas fig trivial alternative would set centers positions randomly selected set patterns method would allow every training pattern figure example uneven coverage two dimensional input space previous knowledge applying radial basis functions directly center neuron fig yet elegant good solution time issue generally method widths fixedly selected reason believe set training samples clustered use clustering methods determine different methods determine clusters arbitrarily dimensional set points introduced excursus one neural clustering method called rolfs section self organizing maps also useful connection determining position rbf neurons section using rolfs one also receive indicators useful radii rbf neurons learning vector quantisation chapter also provided good results methods nothing rbf networks used generate previous knowledge therefore discuss chapter independently indicated chapters another approach use approved methods could slightly move positions centers observe error function err changing gradient descent figure example uneven coverage two dimensional input space applying radial sis functions widths fixedly selected centers neurons randomly distributed throughout training patterns distribution certainly lead slightly unrepresentative results seen single data point left already known mlps similar manner could look error depends values analogous derivation backpropagation derive err err since derivation terms corresponds derivation backpropagation want discuss experience shows convincing results obtained regarding ror behaves depending centers sigmas even mathematics claim methods promising gradient descent already know leads problems craggy error surfaces crucial point naturally rbf networks generate craggy error surfaces considerably change significantly change appearance error function 
[radial, basis, functions, growing, rbf, networks, automatically, adjust, neuron, density] growing rbf networks number rbf neurons constant certain number neurons well centers widths previously selected means clustering method extended reduced following text simple mechanisms sketched information refer 
[radial, basis, functions, growing, rbf, networks, automatically, adjust, neuron, density, neurons, added, places, large, error, values] generating initial configuration vector weights analytically calculated specific errors err concerning set training samples calculated maximum specific error max err sought extension network simple replace maximum error new rbf neuron course exercise care small neurons influence distance short large already exisiting neurons considerably influenced new neuron overlapping gaussian bells obvious adjust already existing rbf neurons adding new neuron put simply adjustment made moving centers neurons away new neuron reducing width bit current output vector network compared teaching input weight vector improved means training subsequently new neuron inserted necessary method particularly suited function approximations 
[radial, basis, functions, growing, rbf, networks, automatically, adjust, neuron, density, limiting, number, neurons] mandatory see network grow infinitum happen fast thus useful previously define maximum number neurons max 
[radial, basis, functions, growing, rbf, networks, automatically, adjust, neuron, density, less, important, neurons, deleted] leads question whether possible continue learning limit max reached answer would stop learning look unimportant neuron delete neuron example unimportant network another neuron similar function often occurs two gaussian bells exactly overlap position instance one single neuron higher gaussian bell would appropriate develop automated procedures order find less relevant neurons highly problem dependent want leave programmer rbf networks multilayer perceptrons already become acquainted extensivley discussed two network paradigms similar problems therefore want compare two paradigms look advantages disadvan tages 
[radial, basis, functions, comparing, rbf, networks, multilayer, perceptrons] compare multilayer perceptrons rbf networks respect different aspects input dimension must careful rbf networks high dimensional func tional spaces since network could quickly require huge memory storage computational effort multilayer perceptron would cause less prob lems number neuons grow exponentially input dimension center selection however selecting centers rbf networks despite introduced approaches still major problem please use previous knowledge applying problems occur mlp output dimension advantage rbf networks training much influenced output dimension network high mlp learning procedure backpropagation thereby time consuming extrapolation advantage well disadvantage rbf networks lack extrapolation capability rbf network returns result far away centers rbf layer one hand extrapolate unlike mlp cannot used extrapolation whereby could never know extrapolated values mlp reasonable experience shows mlps suitable matter hand unlike mlp network capable use tell know could advantage lesion tolerance output mlp important weight neuron missing worsen little total weight neuron missing rbf network large parts output remain practically uninfluenced one part output heavily affected gaussian bell directly missing thus choose strong local error lesion weak global error spread mlp advantaged since rbf networks used considerably less often always understood professionals least far low dimensional input spaces concerned mlps seem considerably longer tradition working good take effort read pages work rbf networks 
[radial, basis, functions, exercises] exercise rbf network fixed widths centers neurons approximate target function training samples form function given let true weights analytically determined means moore penrose pseudo inverse indicate running time behavior regarding precisely possible note methods matrix multiplications matrix inversions efficient canonical methods better estimations recommend look methods complexity addition complexity calculations please indicate used methods together complexity 
[recurrent, perceptronlike, networks] thoughts networks internal states generally recurrent networks networks capable influencing means recurrences including network output following computation steps many types recurrent networks nearly arbitrary form nearly referred recurrent neural networks result paradigms introduced use name recurrent multilayer perceptrons apparently recurrent network capable compute ordinary mlp recurrent weights set recurrent network reduced ordinary mlp additionally recurrence generates different network internal states different inputs produce different outputs context network state recurrent networks great dynamic mathematically difficult conceive discussed extensively aim chapter briefly discuss recurrences structured network internal states generated thus briefly introduce two paradigms recurrent networks afterwards roughly outline training recurrent network input constant time may lead different results one hand network could converge could transform fixed state time return fixed output value hand could never converge least long time later longer recognized consequence constantly changes figure roessler attractor network converge example possible check periodicals attractors fig returned expect complete variety dynamical systems reason particularly want refer literature concerning dynamical systems discussions could reveal happen input recurrent networks changed chapter related paradigms recurrent networks according jordan elman introduced 
[recurrent, perceptronlike, networks, jordan, networks] jordan network multilayer perceptron set called context neurons one context neuron per output neuron fig principle context neuron memorizes output gfed abc gfed abc ttiiiii iiiii iiiii iiiii iiiii gfed abc gfed abc gfed abc gfed abc gfed abc ttiiiii iiiii iiiii iiiii iiiii gfed abc gfed abc figure illustration jordan network network output buffered context neurons next time step entered network together new input processed next time step therefore weighted connections output neuron one context neuron stored values returned actual network means complete links context neurons input layer originial definition jordan network context neurons also recurrent via connecting weight applications omit recurrence since jordan network already dynamic difficult analyze even without additional recurrences definition context neuron context neuron receives output value another neuron time reenters network time definition jordan network jordan network multilayer perceptron one context neuron per output neuron set context neurons called context neurons completely linked toward input layer network gfed abc gfed abc ttiiiii iiiii iiiii iiiii iiiii gfed abc gfed abc gfed abc ttiiiii iiiii iiiii iiiii iiiii onml hijk onml hijk onml hijk gfed abc gfed abc onml hijk onml hijk figure illustration elman network entire information processing part network exists way twice output neuron except output input neurons buffered reentered associated layer reason clarity named context neurons basis models actual network mandatory 
[recurrent, perceptronlike, networks, elman, networks] elman networks variation jordan networks context neurons one layer context neurons per information processing neuron layer fig thus outputs hidden neuron output neuron led associated context layer exactly one context neuron per neuron reentered complete neuron layer next time step complete link way back complete information processing part mlp exists second time context version considerably increases dynamics state variety compared jordan networks elman networks often advantage act purposeful since every layer access context definition elman network elman network mlp one context neuron per information processing neuron set context neurons called remember input layer process information means exists one context layer per information processing neuron layer exactly number context neurons every neuron weighted connection exactly one context neuron context layer completely linked towards original layer interesting take look training recurrent networks since instance ordinary backpropagation error cannot work recurrent networks style following part rather informal means use formal definitions 
[recurrent, perceptronlike, networks, training, recurrent, networks] order explain training comprehensible possible agree simplifications affect learning principle training let assume beginning context neurons ini tiated input since otherwise would undefined input simplification reality furthermore use jordan network without hidden neuron layer training attempts output neurons directly provide input approach strong simplification generally complicated networks used change learning principle 
[recurrent, perceptronlike, networks, training, recurrent, networks, unfolding, time] remember actual learning procedure mlps backpropagation error backpropagates delta values case recurrent networks delta values would backpropagate cyclically network makes training difficult one hand cannot know many generated delta values weight selected training values useful hand cannot definitely know learning stopped advantage recurrent networks great state dynamics within network disadvantage recurrent networks dynamics also granted training therefore make difficult one learning approach would attempt unfold temporal states net work fig recursions deleted putting similar network context neurons context neurons manner speaking output neurons attached network generally spoken backtrack recurrences place earlier instances neurons network thus creating larger forward oriented network without recurrences enables training recurrent network training strategy developed non recurrent ones input entered teaching input every copy input neurons done discrete number time steps training paradigms called folding time unfolding training means backpropagation error possible obviously one weight several changing values received treated differently accumulation averaging etc simple accumulation could possibly result enormous changes per weight changes sign hence also average underestimated could also introduce discounting factor weakens influence past unfolding time particularly useful receive impression closer past important network one away reason backpropagation little influence layers farther away output remember farther output layer smaller influence backpropagation disadvantages training unfolded network take long time since large number layers could possibly produced problem longer negli gible limited computational accuracy ordinary computers exhausted fast many nested computations farther put layer smaller influence backpropagation limit reached furthermore several levels context neurons procedure could produce large networks trained 
[recurrent, perceptronlike, networks, training, recurrent, networks, teacher, forcing] procedures equivalent teacher forcing open loop learning detach recurrence learning process simply pretend currence exist apply teaching input context neurons training backpropagation becomes possible disadvantage elman networks teaching input non output neurons given gfed abc gfed abc gfed abc gfed abc wwnnnn nnnn nnnn nnnn gfed abc ttiiiii iiiii iiiii iiiii iiiii wwnnnn nnnn nnnn nnnn gfed abc gfed abc wwooo ooo ooo ooo ttjjjjj jjjjj jjjjj jjjjj wwooo ooo ooo ooo vvnnnn nnnn nnnn nnnn ttjjjjj jjjjj jjjjj jjjjj jjj wwpppp ppp ppp ppp gfed abc gfed abc gfed abc gfed abc wwnnnn nnnn nnnn nnnn gfed abc ttiiiii iiiii iiiii iiiii iiiii wwnnnn nnnn nnnn nnnn gfed abc gfed abc figure illustration unfolding time small exemplary recurrent mlp top recurrent mlp bottom unfolded network reasons clarity added names lowest part unfolded network dotted arrows leading network mark inputs dotted arrows leading network mark outputs network copy represents time step network recent time step bottom 
[recurrent, perceptronlike, networks, training, recurrent, networks, recurrent, backpropagation] another popular procedure without limited time horizon recurrent backpro pagation using methods differential calculus solve problem 
[recurrent, perceptronlike, networks, training, recurrent, networks, training, evolution] due already long lasting training time evolutionary algorithms proved value especially recurrent networks one reason unrestricted respect recurrences also advantages mutation mechanisms chosen suitably example neurons weights adjusted network topology optimized course result learning necessarily jordan elman network ordinary mlps however evolutionary strategies less popular since certainly need lot time directed learning procedure backpropagation 
[hopfield, networks] magnetic field particle applies force particle particles adjust movements energetically favorable way natural mechanism copied adjust noisy inputs order match real models another supervised learning example wide range neural networks devel oped john hopfield called hopfield networks hopfield physically motivated networks contributed lot renaissance neural networks 
[hopfield, networks, hopfield, networks, inspired, particles, magnetic, field] idea hopfield networks originated behavior particles magnetic field every particle communicates means magnetic forces every particle completely linked particle trying reach energetically favorable state minimum energy function neurons state known activation thus particles neurons rotate thereby encourage continue rotation manner speaking neural network cloud particles based fact particles automatically detect minima energy function hopfield idea use spin particles process information letting particles search minima arbitrary functions even use two spins binary activation recognize developed hopfield network shows considerable dynamics xelt uukkkk kkkk kkkk kkkk kkkk kkkk xelt soo uukkkk kkkk kkkk kkkk kkkk kkkk figure illustration exemplary hopfield network arrows mark binary spin due completely linked neurons layers cannot separated means hopfield network simply includes set neurons 
[hopfield, networks, hopfield, network, neurons, influence, symmetrically] briefly speaking hopfield network consists set completely linked neurons binary activation since use two spins weights symmetric individual neurons without neuron directly connected fig thus state neurons two possible states described string complete link provides full square matrix weights neurons meaning weights discussed following furthermore soon recognize according rules neurons spinning changing state additionally complete link leads fact know input output hidden neurons thus think input something neurons definition hopfield network hopfield network consists set com pletely linked neurons without direct recurrences activation function neu rons binary threshold function outputs definition state hopfield network state network consists activation states neurons thus state network understood binary string 
[hopfield, networks, hopfield, network, neurons, influence, symmetrically, input, output, hopfield, network, represented, neuron, states] learned network set particles state automatically looking minimum input pattern hopfield network exactly state binary string initializes neurons network looking minimum taken previously defined input training samples energy surface know minimum found simple network stops proven hopfield network symmetric weight matrix zeros diagonal always converges point stand still output binary string namely state string network found minimum let take closer look contents weight matrix rules state change neurons definition input output hopfield network input hopfield network binary string initializes state network convergence network output binary string generated new network state 
[hopfield, networks, hopfield, network, neurons, influence, symmetrically, significance, weights] already said neurons change states direction vice versa spins occur dependent current states neurons associated weights thus weights capable control complete change network weights positive negative colloquially speaking weight two neurons following holds positive try force two neurons become equal larger harder network try neuron state neuron state high positive weight advise two neurons energetically favorable equal negative behavior analoguous urged different neuron state would try urge neuron state zero weights lead two involved neurons influencing heaviside function figure illustration binary threshold function weights whole apparently take way current state network towards next minimum energy function want discuss neurons follow way 
[hopfield, networks, hopfield, network, neurons, influence, symmetrically, neuron, changes, state, according, influence, neurons] network trained initialized starting state change state individual neurons occurs according scheme act   time step function act generally binary threshold function fig threshold colloquially speaking neuron calculates sum indicates strong direction neuron forced neurons thus new state network time results state network previous time sum direction neuron pushed depending sign sum neuron takes state another difference hopfield networks already known network topolo gies asynchronous update neuron randomly chosen every time recalculates activation thus new activation previously changed neu rons immediately influences network one time step indicates change single neuron regardless aforementioned random selection neuron hopfield network often much easier implement neurons simply processed one activations recalculated changes occur definition change state hopfield network change state neurons occurs asynchronously neuron updated randomly chosen new state generated means rule act   know weights influence changes states neurons force entire network towards minimum question teach weights force network towards certain minimum 
[hopfield, networks, weight, matrix, generated, directly, training, patterns] aim generate minima mentioned energy surface input network converge many network paradigms use set training patterns representing minima energy surface unlike many network paradigms look minima unknown error function define minima function purpose network shall automatically take closest minimum input presented seems unusual understand whole purpose later roughly speaking training hopfield network done training training pattern exactly using rule described following single shot learning states neurons results weight matrix colloquially speaking initialize network means training pattern process weights one another weights verify neurons state states vary first case add weight second case add repeat training pattern finally values weights high corresponded many training patterns colloquially speaking high value tells neurons often energetically favorable hold state applies negative weights due training store certain fixed number patterns weight matrix input network converge stored pattern closest input unfortunately number maximum storable reconstructible patterns limited max turn applies orthogonal patterns shown precise time consuming mathematical analyses want specify patterns entered already stored information destroyed definition learning rule hopfield networks individual elements weight matrix defined single processing learning rule diagonal matrix covered zeros max training samples trained time maintain func tion know functionality hopfield networks nothing practical use 
[hopfield, networks, autoassociation, traditional, application] hopfield networks like mentioned called autoassociators autoas sociator exactly shows aforementioned behavior firstly known pattern entered exactly known pattern returned thus associative mapping secondly practical use also works inputs close pattern afterwards autoassociator case stable state namely state set patterns consists example letters characters form pixels network able correctly recognize deformed noisy letters high probability fig primary fields application hopfield networks pattern recognition pattern completion zip code recognition letters eighties soon hopfield networks replaced systems fields application example ocr systems field letter recognition today hopfield networks virtually longer used become established practice 
[hopfield, networks, heteroassociation, analogies, neural, data, storage] far introduced hopfield networks converge arbitrary input closest minimum static energy surface another variant dynamic energy surface appearance energy surface depends current state receive heteroassociator instead autoassociator heteroassociator longer true rather means pattern mapped onto another one heteroassociative mapping heteroassociations achieved means asymmetric weight matrix figure illustration convergence exemplary hopfield network pictures binary pixels hopfield network pixel corresponds one neuron upper illustration shows training samples lower shows convergence heavily noisy corresponding training sample heteroassociations connected series form provoke fast cycle states whereby single pattern never completely accepted pattern entirely completed heteroassociation already tries generate successor pattern additionally network would never stop since reached last state would proceed first state 
[hopfield, networks, heteroassociation, analogies, neural, data, storage, generating, heteroassociative, matrix] generate matrix means elements similar autoassociative matrix per transition training sample transition training sample generated diagonal matrix filled zeros neuron states always adapted operation several transitions introduced matrix simple addition whereby said limitation exists definition learning rule heteroassociative matrix two training samples predecessor successor heteroassociative transition weights heteroassociative matrix result learning rule several heteroassociations introduced network simple addition 
[hopfield, networks, heteroassociation, analogies, neural, data, storage, stabilizing, heteroassociations] already mentioned problem patterns completely generated next pattern already beginning generation previous pattern finished problem avoided influencing network means heteroassociative matrix also already known autoassociative matrix additionally neuron adaptation rule changed competing terms gener ated one term autoassociating existing pattern one term trying convert pattern successor associative rule provokes network stabilizes pattern remains goes next pattern act       autoassociation heteroassociation value causes descriptively speaking influence matrix delayed since refers network versions behind result change state individual states stable short set example twenty steps asymmetric weight matrix realize change network twenty steps later initially works autoassociative matrix since still perceives predecessor pattern current one work 
[hopfield, networks, heteroassociation, analogies, neural, data, storage, biological, motivation, heterassociation] biological point view transition stable states stable states highly motivated least beginning nineties assumed hopfield modell achieve approximation state dynamics brain realizes much means state chains would ask dear reader recite alphabet generally manage better please try immediately answer following question letter alphabet follows letter fermi function temperature parameter figure already known fermi function different temperature parameter variations another example phenomenon one cannot remember situation place one memorized last time perfectly known one returns place forgotten situation often comes back mind 
[hopfield, networks, continuous, hopfield, networks] far discussed hopfield networks binary activations hopfield also described version networks continuous activations want cover least briefly continuous hopfield networks activation longer calculated binary threshold function fermi function temperature parameters fig network stable symmetric weight matrices zeros diagonal hopfield also stated continuous hopfield networks applied find accept able solutions hard travelling salesman problem according verification trials statement kept today faster algorithms handling problem therefore hopfield network longer used 
[hopfield, networks, exercises] exercise indicate storage requirements hopfield network neurons weights shall stored integers possible limit value range weights order save storage space exercise compute weights hopfield network using training set 
[learning, vector, quantization] learning vector quantization learning procedure aim represent vector training sets divided predefined classes well possible using representative vectors managed vectors unkown could easily assigned one classes slowly part text nearing end therefore want write last chapter part smooth transition next one chapter learning vector quantization abbreviated lvq described teuvo kohonen characterized related self organizing feature maps soms described next chapter already belongs part text since soms learn unsupervised thus exploration lvq want bid farewell supervised learning previously want announce different variations lvq mentioned exactly represented goal chapter rather analyze underlying principle 
[learning, vector, quantization, quantization] order explore learning vector quantization first get clearer picture quantization also referred discretization everybody knows sequence discrete numbers contains natural numbers discrete means sequence consists separated elements interconnected elements example actly numbers natural numbers include example numbers hand sequence real numbers instance continuous matter close two selected numbers always number quantization means continuous space divided discrete sections delet ing example decimal places real number could assigned natural number obvious number front comma would also assigned natural number would kind representative real numbers within interval must noted sequence irregularly quantized instance timeline week could quantized working days weekend special case quantization digitization case digitization always talk regular quantization continuous space number system respect certain basis enter example numbers computer numbers digitized binary system basis definition quantization separation continuous space discrete sec tions definition digitization regular quantization 
[learning, vector, quantization, lvq, divides, input, space, separate, areas] almost possible describe means name lvq enable set representatives used divide input space classes reflect input space well possible fig thus element input space assigned vector representative class set representatives represent entire input space precisely possible vector called codebook vector codebook vector representative exactly input space vectors lying closest divides input space said discrete areas emphasized know advance many classes training sample belongs class furthermore important classes must disjoint means may overlap figure bexamples quantization two dimensional input space dthe lines represent class limit mark codebook vectors separation data classes interesting many problems useful explore characteristic representatives instead possibly huge set vectors less time consuming sufficiently precise 
[learning, vector, quantization, using, codebook, vectors, nearest, one, winner] use prepared set codebook vectors simple input vector class association easily decided considering codebook vector closest codebook vectors build voronoi diagram set since codebook vector clearly associated class input vector associated class 
[learning, vector, quantization, adjusting, codebook, vectors] already indicated lvq supervised learning procedure thus teaching input tells learning procedure whether classification input pattern right wrong words know advance number classes represented number codebook vectors roughly speaking aim learning procedure training samples used cause previously defined number randomly initialized codebook vectors reflect training data precisely possible 
[learning, vector, quantization, adjusting, codebook, vectors, procedure, learning] learning works according simple scheme since learning supervised set training samples additionally already know classes predefined also set classes codebook vector clearly assigned class thus say set classes contains many codebook vectors leads structure training samples form therefore contain training input vector class affiliation class affiliation holds means clearly assigns training sample class codebook vector intuitively could say learning learning procedure calculate average class members place codebook vectors see soon learning procedure lot want briefly discuss steps fundamental lvq learning procedure initialization place set codebook vectors random positions input space training sample training sample training set selected presented distance measurement measure distance codebook vec tors input winner closest codebook vector wins one min learning process learning process takes place according rule want break already seen first factor time dependent learning rate allowing differentiate large learning steps fine tuning last factor obviously direction toward codebook vector moved function core rule implements distinction cases assignment correct winner vector codebook vector class includes case function provides positive values codebook vector moves towards assignment wrong winner vector represent class cludes therefore moves away see definition function precise enough good reason lvq divided different nuances dependent actly learning rate defined called lvq lvq lvq olvq etc differences instance strength codebook vector move ments based principle described announced want discuss therefore give formal definition regarding aforementioned learning rule lvq 
[learning, vector, quantization, connection, neural, networks] spite learning process question lvq neural networks codebook vectors understood neurons fixed position within input space similar rbf networks additionally nature often occurs group one neuron may fire winner neuron codebook vector return inhibits neurons decided place brief chapter learning vector quantization approach continued following chapter self organizing maps classify inputs means neurons distributed throughout input space time know input belongs class let take look unsupervised learning networks 
[learning, vector, quantization, exercises] exercise indicate quantization equally distributes vectors five dimensional unit cube one classes 
[self-organizing, feature, maps] paradigm unsupervised learning neural networks maps input space fixed topology thus independently looks simililarities function learning procedure variations neural gas take look concepts biological neural networks mentioned intro duction one question arise brain store recall impressions receives every day let point brain training samples therefore desired output already considering subject realize output sense brain responds external input changes state speak output based principle exploring question biological neural networks organize teuvo kohonen developed eighties self organizing feature maps shortly referred self organizing maps soms paradigm neural networks output state network learns completely unsupervised without teacher unlike network paradigms already got know soms unnecessary ask neurons calculate ask neuron active moment biologically motivated biology neurons connected certain muscles less interesting know strong certain muscle contracted muscle activated words interested exact output neuron knowing neuron provides output thus soms considerably related biology example feedforward networks increasingly used calculations 
[self-organizing, feature, maps, structure, self-organizing, map] typically soms like brain task map high dimensional input dimensions onto areas low dimensional grid cells dimensions draw map high dimensional space speak generate map som simply obtains arbitrary many points input space input points som try cover good possible positions points appear neurons particularly means every neuron assigned certain position input space first facts seem bit confusing recommended briefly reflect two spaces soms working dimensional input space dimensional grid neurons lying indicates neighborhood relationships neurons therefore network topology one dimensional grid neurons could instance like pearls string every neuron would exactly two neighbors except two end neurons two dimensional grid could square array neurons fig another possible array two dimensional space would kind honeycomb shape irregular topologies possible often topolgies dimensions considerably neighborhood relationships would also possible due lack visualization capability employed often even true two spaces equal distinguished special case dimension initially briefly formally regard functionality self organizing map make clear means examples definition som neuron similar neurons rbf network som neuron occupy fixed position center input space definition self organizing map self organizing map set som neurons input vector entered exactly neuron activated closest input pattern input space dimension input space referred definition topology neurons interconnected neighborhood lationships neighborhood relationships called topology training figure example topologies self organizing map see one dimensional topology two dimensional one som highly influenced topology defined topology function winner neuron ist neuron adapted discussed later timestep dimension topology referred 
[self-organizing, feature, maps, soms, always, activate, neuron, least, distance, input, pattern] like many neural networks som trained used let regard simple functionality complete self organizing map training since many analogies training functionality consists following steps input arbitrary value input space calculation distance every neuron means norm calculation learn soon winner neuron one neuron becomes active namely neuron shortest calculated dis tance input neurons remain inactive paradigm activity also called winner takes scheme output expect due input som shows neuron becomes active many literature citations description soms formal often input layer described completely linked towards som layer input layer neurons forwards inputs som layer som layer laterally linked winner neuron established inhibit neurons think explanation som descriptive therefore tried provide clearer description network structure question neuron activated input answer given network training 
[self-organizing, feature, maps, training] training makes som topology cover input space training som nearly straightforward functionality described basically struc tured five steps partially correspond functionality initialization network starts random neuron centers input space creating input pattern stimulus point selected input space stimulus entered network distance measurement distance determined every neuron network winner takes winner neuron determined smallest dis tance fulfills condition see several winner neurons one selected adapting centers neuron centers moved within input space according rule values simply added existing centers last factor shows change position neurons proportional distance input pattern usual time dependent learning rate mentioned network topology exerts influence means function discussed following definition som learning rule som trained presenting input pattern determining associated winner neuron winner neuron neighbor neurons defined topology function adapt centers according rule 
[self-organizing, feature, maps, training, topology, function, defines, learning, neuron, influences, neighbors] topology function defined input space grid represents neighborhood relationships neurons topology network time dependent often explains parameter parameter index running neurons parameter index winner neuron principle function shall take large value neighbor winner neuron even winner neuron small values smore precise defini tion topology function must unimodal must exactly one maximum maximum must next winner neuron distance certainly additionally time dependence enables example reduce neighborhood course time note many sources rule written wrongly leads reader believe constant problem easily solved omitting multiplication dots figure example distances one dimensional som topology two dimensional som topology two neurons lower case euclidean distance determined two dimensional space equivalent pythagoream theorem upper case simply count discrete path length simplify matters required fixed grid edge length cases order able output large values neighbors small values non neighbors function needs kind distance notion grid somewhere know far apart grid different methods calculate distance two dimensional grid could apply instance euclidean distance lower part fig one dimensional grid could simply use number connections neurons upper part figure definition topology function topology function describes neighborhood relationships topology unimodal function reaches maximum gilt time dependence optional often used introduction common distance topology functions common distance function would example already known gaussian bell see fig unimodal maximum close additionally width changed applying parameter used realize neighborhood reduced course time simply relate time dependence result monotonically decreasing topology function could look like represent neuron positions grid neuron positions input space would referred functions used instead gaussian function instance cone function cylinder function mexican hat function fig mexican hat function offers particular biological motivation due negative digits rejects neurons close winner neuron behavior already observed nature cause sharply separated map areas exactly mexican hat function suggested teuvo kohonen adjustment characteristic necessary functionality map could even possible map would diverge could virtually explode 
[self-organizing, feature, maps, training, learning, rates, neighborhoods, decrease, monotonically, time] avoid later training phases forcefully pull entire map towards new pattern soms often work temporally monotonically decreasing learning rates neighborhood sizes first let talk learning rate typical sizes target value learning rate two sizes smaller initial value could true size must also depend network topology size neighborhood already seen decreasing neighborhood size realized example means time dependent monotonically decreasing gaussin bell used topology function gaussian cone function cylinder funktion mexican hat function figure gaussian bell cone function cylinder function mexican hat function sug gested kohonen examples topology functions som advantage decreasing neighborhood size beginning moving neuron pulls along many neurons vicinity randomly initialized network unfold fast properly beginning end learning process neurons influenced time stiffens network whole enables good fine tuning individual neurons must noted must always true since otherwise neurons would constantly miss current training sample enough theory let take look som action 
[self-organizing, feature, maps, examples, functionality, soms] let begin simple mentally comprehensible example example use two dimensional input space true let grid structure one dimensional furthermore example som consist neurons learning rate neighborhood function also kept simple able mentally comprehend network direct neighbor otherw let take look mentioned network random initialization centers fig enter training sample obviously example input pattern closest neuron winning neuron remember learning rule soms process three factors back learning direction remember neuron centers vectors input space well pattern thus factor indicates vector neuron pattern multiplied different scalars xfgt figure illustration two dimensional input space left one dimensional topolgy space right self organizing map neuron winner neuron since closest topology neurons neighbors arrows mark movement winner neuron neighbors towards training sample illustrate one dimensional topology network plotted input space dotted line arrows mark movement winner neuron neighbors towards pattern topology function indicates winner neuron two closest neighbors allowed learn returning neurons time dependence specified thus vector multiplied either learning rate indicates always strength learning already mentioned result winner neuron neighbors approximate pattern half way figure marked arrows although center neuron seen input space considerably closer input pattern neuron neuron learning neuron want remind network topology specifies neuron allowed learn position input space exactly mechanism topology significantly cover input space without related sort adaptation neurons next pattern applied another example one dimensional som develop two dimensional input space uniformly distributed input patterns course time seen figure end states one two dimensional soms differently shaped input spaces seen figure see every input space neatly covered every network topology called exposed neurons neurons located area input pattern ever occurred one dimensional topology generally produces less exposed neurons two dimensional one instance training circularly arranged input patterns nearly impossible two dimensional squared topology avoid exposed neurons center circle pulled every direction training finally remain center make one dimensional topology optimal topology since find less complex neighborhood relationships multi dimensional one 
[self-organizing, feature, maps, examples, functionality, soms, topological, defects, failures, som, unfolding] unfolding som could happen topological defect fig occurs som unfold correctly topological defect described best means word knotting remedy topological defects could increase initial values neigh borhood size complex topology neighbors figure behavior som one dimensional topology input randomly distributed input patterns training decreased parameter gauss function decreased figure end states one dimensional left column two dimensional right column soms different input spaces neurons used one dimensional topology neurons two dimensionsal topology input patterns maps figure topological defect two dimensional som neuron respectively since three dimensional honeycombed two dimensional topology could also generated difficult randomly initialized map unfold 
[self-organizing, feature, maps, possible, adjust, resolution, certain, areas, som] seen som trained entering input patterns input space one another som aligned patterns map could happen want certain subset input space mapped precise ones problem easily solved means soms training dispropor tionally many input patterns area presented som number training patterns presented som exceeds number pat figure training som two dimensional input space left side chance become training pattern equal coordinate input space right side central circle input space chance ten times larger remaining input space visible larger pattern density background circle neurons obviously crowded remaining area covered less dense cases neurons still evenly distributed two soms trained means training samples decreasing well decreasing terns remaining neurons group remaining neurons sparsely distributed fig see illustration edge som could deformed compensated assigning edge input space slightly higher probability hit training patterns often applied approach reaching every corner soms also higher learning rate often used edge corner neurons since pulled center topology also results significantly improved corner coverage 
[self-organizing, feature, maps, application, soms] regarding biologically inspired associative data storage many fields application self organizing maps variations example different phonemes finnish language successfully mapped onto som two dimensional discrete grid topology therefore neighborhoods found som nothing else finding neighborhood relationships one tries break high dimensional space low dimensional space topology looks structures developed voilà clearly defined areas individual phenomenons formed teuvo kohonen made effort search many papers mentioning soms keywords large input space individual papers individual positions depending occurrence keywords kohonen created som used map high dimensional paper space developed thus possible enter paper completely trained som look neuron som activated likely discover neighbored papers topology interesting type brain like context based search also works many input spaces noted system defines neighbored similar within topology interesting example shows position neurons input space signifi cant rather interesting see neuron activated unknown input pattern entered next look previous inputs neuron also activated immediately discover group similar inputs inputs within topology diverging less things com mon virtually topology generates map input characteristics reduced descriptively dimensions relation input dimension therefore topology som often two dimensional easily visualized input space high dimensional 
[self-organizing, feature, maps, application, soms, soms, used, determine, centers, rbf, neurons] soms arrange exactly towards positions outgoing inputs result used example select centers rbf network already introduced paradigm rbf network chapter already seen possible control areas input space covered higher resolution connection rbf networks areas function rbf network work neurons work exactly useful feature combination rbf networks soms one use topology obtained som final training rbf neuron used influence neighboring rbf neurons different ways many neural network simulators offer additional called som layer connection simulation rbf networks 
[self-organizing, feature, maps, variations, soms] different variations soms different variations representation tasks 
[self-organizing, feature, maps, variations, soms, neural, gas, som, without, static, topology] neural gas variation self organizing maps thomas martinetz developed difficulty mapping complex input information partially occur subspaces input space even change subspaces fig idea neural gas roughly speaking realize som without grid structure due fact derived soms learning steps similar som learning steps include additional intermediate step random initialization selection presentation pattern input space neuron distance measurement identification winner neuron intermediate step generation list neurons sorted ascending order distance winner neuron thus first neuron list neuron closest winner neuron changing centers means known rule slightly modified topology function figure figure filling different subspaces actual input space different positions therefore hardly filled som function slightly modified compared original function regards first elements list neighborhood winner neuron direct result similar free floating molecules gas neighborhood relationships neurons change anytime number neighbors almost arbitrary distance within neighborhood represented distance within input space bulk neurons become stiffened som means constantly decreasing neighborhood size fixed dimension take dimension locally needed moment advantageous disadvantage could fixed grid forcing input space become regularly covered therefore wholes occur cover neurons isolated spite practical hints always user responsibility understand text catalog easy answers explore advantages disadvantages unlike som neighborhood neural gas must initially refer neurons since otherwise outliers random initialization may never reach remaining group forget popular error implementation neural gas neural gas possible learn kind complex input fig since bound fixed dimensional grid computational effort could necessary permanent sorting list could effective store list ordered data structure right start definition neural gas neural gas differs som completely dynamic neighborhood function every learning cycle decided anew neurons neigborhood neurons winner neuron generally criterion decision distance neurosn winner neuron input space 
[self-organizing, feature, maps, variations, soms, multi-som, consists, several, separate, soms] order present another variant soms want formulate extended problem input patterns know confined different maybe disjoint areas idea use one som several ones multi self organizing map shortly referred som unnecessary soms topology size som combination soms learning process analog soms however neurons belonging winner som training step adapted thus easy represent two disjoint clusters data means two soms even one clusters represented every dimension input space actually individual soms exactly reflect clusters definition multi som multi som nothing simultaneous use soms 
[self-organizing, feature, maps, variations, soms, multi-neural, gas, consists, several, separate, neural, gases] analogous multi som also set neural gases multi neural gas construct behaves analogous neural gas som neurons winner gas adapted reader certainly wonders advantage use multi neural gas since individual neural gas already capable divide clusters work complex input patterns changing dimensions basically correct multi neural gas two serious advantages simple neural gas several gases directly tell neuron belongs gas particularly important clustering tasks multi neural gases used recently simple neural gases also find cover clusters cannot recognize neuron belongs cluster lot computational effort saved large original gases divided several smaller ones since already mentioned sorting list could use lot computational effort sorting several smaller lists less time consuming even lists total contain number neurons result obtain local instead global sortings cases local sortings sufficient choose two extreme cases multi neural gases one extreme case ordinary neural gas use one single neural gas interesting enough extreme case large one neuron per gas behaves analogously means clustering information clustering procedures see excursus definition multi neural gas multi neural gas nothing simultaneous use neural gases 
[self-organizing, feature, maps, variations, soms, growing, neural, gases, add, neurons] growing neural gas variation aforementioned neural gas neurons added according certain rules thus attempt work isolation neurons generation larger wholes cover subject mentioned discussed build growing som difficult new neurons integrated neighborhood 
[self-organizing, feature, maps, exercises] exercise regular two dimensional grid shall cover two dimensional surface well possible grid structure would suit best purpose criteria use well best imprecise formulation exercise intentional 
[adaptive, resonance, theory] art network original form shall classify binary input vectors assign output simultaneously far unclassified patterns shall recognized assigned new class smaller chapters want try figure basic idea adaptive resonance theory abbreviated art without discussing theory pro foundly several sections already mentioned difficult use neural networks learning new information addition without destroying already existing information circumstance called stability plasticity dilemma stephen grossberg gail carpenter published first version art network order alleviate problem followed whole family art improvements want discuss briefly idea unsupervised learning whose aim initially binary pattern recog nition precisely categorization patterns classes additionally art network shall capable find new classes 
[adaptive, resonance, theory, task, structure, art, network] art network comprises exactly two layers input layer recognition layer input layer completely linked towards recognition layer complete link induces top weight matrix contains weight values connections neuron input layer neuron recognition layer fig gfed abc gfed abc xxx xxx xxx xxx xxx xxx xxx gfed abc wwooo ooo ooo ooo ooo ooo ooo ooo ooo xxx xxx xxx xxx xxx xxx xxx gfed abc uukkkk kkkk kkkk kkkk kkkk kkkk kkkk kkkk kkkk wwooo ooo ooo ooo ooo ooo ooo ooo ooo xxx xxx xxx xxx xxx xxx xxx gfed abc gfed abc gfed abc gfed abc ccffff ffff ffff ffff ffff gfed abc ggooooo ooooo ooooo ooooo ooooo oooo ccffff ffff ffff ffff ffff gfed abc iisssssss sssssss sssssss sssssss sssssss sss ggooooo ooooo ooooo ooooo ooooo oooo ccffff ffff ffff ffff ffff figure simplified illustration art network structure top input layer bottom recognition layer illustration lateral inhibition recognition layer control neurons omitted simple binary patterns entered input layer transferred recogni tion layer recognition layer shall return encoding follow winner takes scheme instance realize encoding principle lateral inhibition used implementation activated neuron searched practical reasons query would suit task best 
[adaptive, resonance, theory, task, structure, art, network, resonance, takes, place, activities, tossed, turned] also exists bottom weight matrix propagates activities within recognition layer back input layer obvious tivities bounced forth back fact leads resonance every activity within input layer causes activity within recognition layer turn recognition layer every activity causes activity within input layer addition two mentioned layers art network also exist neurons exercise control functions signal enhancement want discuss theory since basic principle art network become explicit mentioned explain spite recurrences art network achieve stable state input 
[adaptive, resonance, theory, learning, process, art, network, divided, top-down, bottom-up, learning] trick adaptive resonance theory configuration art network also two piece learning procedure theory one hand train top matrix hand train bottom matrix fig 
[adaptive, resonance, theory, learning, process, art, network, divided, top-down, bottom-up, learning, pattern, input, top-down, learning] pattern entered network causes already mentioned activation output neurons strongest neuron wins weights matrix going towards output neuron changed output strongest neuron still enhanced class affiliation input vector class output neuron becomes enhanced 
[adaptive, resonance, theory, learning, process, art, network, divided, top-down, bottom-up, learning, resonance, bottom-up, learning] training backward weights matrix bit tricky weights respective winner neuron trained towards input layer current input pattern used teaching input thus network trained enhance input vectors 
[adaptive, resonance, theory, learning, process, art, network, divided, top-down, bottom-up, learning, adding, output, neuron] course could happen neurons nearly equally activated several neurons activated network indecisive case mechanisms control neurons activate signal adds new output neuron current pattern assigned output neuron weight sets new neuron trained usual kapitel adaptive resonance theory dkriesel com gfed abc gfed abc gfed abc gfed abc gfed abc gfed abc gfed abc gfed abc gfed abc gfed abc gfed abc gfed abc gfed abc gfed abc gfed abc gfed abc gfed abc gfed abc bbff abbildung vereinfachte darstellung des zweigeteilten trainings eines art netzes die jeweils trainierten gewichte sind durchgezogen dargestellt nehmen wir ein muster wurde das netz eingegeben und die zahlen markieren ausgaben oben wir wir sehen ist das winnerneuron mitte also werden die gewichte zum gewinnerneuron hin trainiert und unten die gewichte vom gewinnerneuron zur eingangs schicht trainiert einer abfrage die man den mecha nismus eines neuronalen netzes gepresst hat 
[adaptive, resonance, theory, erweiterungen] wie schon eingangs erw ahnt wurden die art netze vielfach erweitert art ist eine erweiterung auf kontinuierliche eingaben und bietet zus atzlich einer art genannten erweiterung verbesserungen der lernge schwindigkeit zus atzliche kontroll neurone und schichten zur folge hat art verbessert die lernf ahig keit von art indem zus atzliche biolo gische vorg ange wie die chemischen vorg ange innerhalb der synapsen adap tiert werden zus atzlich den beschriebenen erweite rungen existieren noch viele mehr durch die aufigen erweiterungen der adaptive resonance theory sprechen ose zungen bereits von art netzen kriesel ein kleiner uberblick uber neuronale netze epsilon figure simplified illustration two piece training art network trained weights represented solid lines let assume pattern entered network numbers mark outputs top see winner neuron middle weights trained towards winner neuron weights winner neuron trained towards input layer thus advantage system divide inputs classes find new classes also tell activation output neuron typical representative class looks like significant feature often however system moderately distinguish patterns question new neuron permitted become active learn art network different additional control neurons answer question according different mathematical rules responsible intercepting special cases time one largest objections art fact art network uses special distinction cases similar query forced mechanism neural network 
[adaptive, resonance, theory, extensions] already mentioned art networks often extended art extended continuous inputs additionally offers exten sion called art enhancements learning speed results additional control neurons layers art improves learning ability art adapting additional bio logical processes chemical processes within synapses apart described ones exist many extensions frequent extensions adaptive resonance theory wagging tongues already call art networks 
[excursus, cluster, analysis, regional, online, learnable, fields] grimm dictionary extinct german word kluster described dicht und dick zusammensitzet thick dense group sth static cluster analysis formation groups within point clouds explored introduction procedures comparison advantages disadvantages discussion adaptive clustering method based neural networks regional online learnable field models point cloud possibly lot points comparatively small set neurons representative point cloud already mentioned many problems traced back problems cluster analysis therefore necessary research procedures examine whether groups called clusters exist within point clouds since cluster analysis procedures need notion distance two points metric must defined space points situated briefly want specify metric definition metric relation dist defined two objects referred metric following criteria applies dist dist dist symmetry dist dist dist triangle inequality holds colloquially speaking metric tool determining distances points space distances symmetrical distance points may two points equal additionally triangle inequality must apply metrics provided example squared distance euclidean distance already introduced based metrics define clustering procedure uses metric distance measure want introduce briefly discuss different clustering procedures 
[excursus, cluster, analysis, regional, online, learnable, fields, k-means, clustering, allocates, data, predefined, number, clusters] means clustering according macqueen algorithm often used low computation storage complexity regarded inexpensive good operation sequence means clustering algorithm following provide data examined define number cluster centers select random vectors cluster centers also referred codebook vectors assign data point next codebook vector compute cluster centers clusters set codebook vectors new cluster centers continue assignments longer changed step already shows one great questions means algorithm number cluster centers determined advance cannot done algorithm problem necessarily known advance determined best another problem procedure become quite instable codebook vectors badly initialized since random often useful restart procedure advantage requiring much computational effort fully aware weaknesses receive quite good results name codebook vector created often used name cluster vector unclear however complex structures clusters clusters cannot recognized high outer ring construction following illustration recognized many single clusters low ring small inner clusters recognized one cluster illustration see upper right part fig 
[excursus, cluster, analysis, regional, online, learnable, fields, k-nearest, neighboring, looks, nearest, neighbors, data, point] nearest neighboring procedure connects data point closest neighbors often results division groups group builds cluster advantage number clusters occurs disadvantage large storage computational effort required find next neighbor distances data points must computed stored special cases procedure combines data points belonging different clusters high see two small clusters upper right illustration clusters consisting one single data point basically conncted another cluster always intentional furthermore mandatory links points symmetric procedure allows recognition rings therefore clusters clusters clear advantage another advantage procedure adaptively sponds distances clusters illustration see lower left part fig 
[excursus, cluster, analysis, regional, online, learnable, fields, -nearest, neighboring, looks, neighbors, within, radius, data, point] another approach neighboring neighborhood detection use fixed number neighbors radius reason name epsilon nearest neighboring points neigbors apart storage computational effort obviously high disadvantage note special cases two separate clusters easily con nected due unfavorable situation single data point also happen nearest neighboring would difficult since case number neighbors per point limited advantage symmetric nature neighborhood relationships another vantage combination minimal clusters due fixed number neighbors avoided hand necessary skillfully initialize order successful smaller half smallest distance two clusters variable cluster point distances within clusters possibly problem illustration see lower right part fig 
[excursus, cluster, analysis, regional, online, learnable, fields, silhouette, coefficient, determines, accurate, given, clustering] see easy answer clustering problems procedure described specific disadvantages respect useful criterion decide good cluster division possibility offered silhouette coefficient according coefficient measures well clusters delimited indicates points may assigned wrong clusters let point cloud point let cluster within point cloud part cluster set clusters called summary applies calculate silhouette coefficient initially need average distance point cluster neighbors variable referred defined follows dist figure top left set points use set explore different clustering methods top right means clustering using procedure chose see procedure capable recognize clusters clusters bottom left illustration long lines points problem would recognized many small clusters sufficiently large bottom left nearest neighboring selected high higher number points smallest cluster result cluster combinations shown upper right illustration bottom right nearest neighboring procedure cause difficulties selected larger minimum distance two clusters see upper left illustration combined furthermore let average distance point points next cluster represents clusters except min dist point classified well distance center cluster minimal distance centers clusters maximal case following term provides value close max apparently whole term within interval value close indicates bad classification silhouette coefficient results average values total quality cluster division expressed interval different clustering strategies different characteristics presented lots material presented well measure indicate quality existing arrangement given data clusters want introduce clustering method based unsupervised learning neural network published like methods one may perfect eliminates large standard weaknesses known clustering methods 
[excursus, cluster, analysis, regional, online, learnable, fields, regional, online, learnable, fields, neural, clustering, strategy] paradigm neural networks want introduce regional online learnable fields shortly referred rolfs 
[excursus, cluster, analysis, regional, online, learnable, fields, regional, online, learnable, fields, neural, clustering, strategy, rolfs, try, cover, data, neurons] roughly speaking regional online learnable fields set neurons try cover set points well possible means distribution input space neurons added moved changed size training necessary parameters individual neurons discussed later definition regional online learnable field regional online learnable field abbreviated rolf rolf network set neurons trained cover certain set input space well possible rolf neurons feature position radius input space rolf neuron two parameters similar rbf networks center position input space yet another parameter radius defines radius perceptive surface surrounding neuron neuron covers part input space situated within radius locally defined neuron particularly means neurons capable cover surfaces different sizes radius perceptive surface specified fig multiplier globally defined previously specified neurons intuitively reader wonder multiplicator used significance discussed later furthermore following observed necessary perceptive surface different neurons size definition rolf neuron parameters rolf neuron center radius definition perceptive surface perceptive surface rolf neuron consists points within radius input space 
[excursus, cluster, analysis, regional, online, learnable, fields, regional, online, learnable, fields, neural, clustering, strategy, rolf, learns, unsupervised, presenting, training, samples, online] like many paradigms neural networks rolf network learns receiving many training samples training set learning unsupervised training sample entered network two cases occur one accepting neuron accepting neuron first case several neurons suitable exactly one accepting neuron insofar closest neuron accepting one accepting neuron adapted write defines actual radius specified figure structure rolf neuron definition accepting neuron criterion rolf neuron accepting neuron point point must located within perceptive surface located perceptive surfaces several neurons closest neuron accepting one several closest neurons one chosen randomly positions radii adapted throughout learning let assume entered training sample network accepting neuron radius moves towards towards distance center towards additionally let define two learning rates radii centers note scalar vector input space definition adapting rolf neuron neuron accepted point adapted according following rules radius multiplier allows neurons able shrink understand function multiplier due multiplier perceptive surface neuron includes points surrounding neuron radius means due aforementioned learning rule cannot decrease also increase definition radius multiplier radius multiplier globally defined expands perceptive surface neuron multiple ensured radius cannot decrease also increase generally radius multiplier set values lower one digit range far discussed case rolf training accepting neuron training sample required new neurons generated suggests discuss approach case accepting neuron case new accepting neuron generated training sample result course initialized initialization understood intuitively center new neuron simply set training sample generate new neuron neuron close logical reasons place neuron exactly set new neuron generated purpose exist different options init always select predefined static minimum take look neuron select minimum maximum take look neuron select maximum mean select mean neurons currently mean variant favorite one although learning procedure also works ones minimum variant neurons tend cover less surface maximum variant tend cover surface definition generating rolf neuron new rolf neuron generated entering training sample intialized according one aforementioned strategies init minimum maximum mean training complete repeated randomly permuted pattern presentation new neuron generated epoch positions neurons barely change 
[excursus, cluster, analysis, regional, online, learnable, fields, regional, online, learnable, fields, neural, clustering, strategy, evaluating, rolf] result training algorithm training set gradually covered well precisely rolf neurons high concentration points spot input space automatically generate neurons thus possibly large point cloud reduced representatives based input set easy define number clusters two neurons according definition rolf connected perceptive surfaces overlap kind nearest neighboring executed variable perceptive surfaces cluster group connected neurons group points input space covered neurons fig course complete rolf network evaluated means clustering methods neurons searched clusters particularly clustering methods whose storage effort grows quadratic storage effort reduced dramatically since generally considerably less rolf neurons original data points neurons represent data points quite well figure clustering process top input set middle input space covered rolf neurons bottom input space covered neurons representatives 
[excursus, cluster, analysis, regional, online, learnable, fields, regional, online, learnable, fields, neural, clustering, strategy, comparison, popular, clustering, methods] obvious storing neurons rather storing input points takes biggest part storage effort rolfs great advantage huge point clouds lot points since unnecessary store entire point cloud rolf neural clustering method capability learn online definitely great advantage fur thermore similar nearest neighboring nearest neighboring distinguish clusters enclosed clusters due online presentation data without quadratically growing storage effort far greatest disadvantage two neighboring methods additionally issue size individual clusters proportional dis tance addressed using variable perceptive surfaces also always case two mentioned methods rolf compares favorably means clustering well firstly unnec essary previously know number clusters secondly means clustering recognizes clusters enclosed clusters separate clusters 
[excursus, cluster, analysis, regional, online, learnable, fields, regional, online, learnable, fields, neural, clustering, strategy, initializing, radii, learning, rates, multiplier, trivial] certainly disadvantages rolf shall concealed always easy select appropriate initial value previous knowledge data set say included initial value rolf fine grained data clusters use small small initial value smaller smaller chance neurons grow necessary easy answer like learning rates multipliers lower single digit range popular successfully work values variations run time also imaginable type network initial values generally depend cluster data distribution often tested compared wrong initializations least mean strategy relatively robust training time whole rolf par clustering methods particularly interesting systems low storage capacity huge data sets 
[excursus, cluster, analysis, regional, online, learnable, fields, regional, online, learnable, fields, neural, clustering, strategy, application, examples] first application example could finding color clusters rgb images another field application directly described rolf publication recognition words transferred dimensional feature space thus see rolfs relatively robust higher dimensions applications found field analysis attacks network systems classification 
[excursus, cluster, analysis, regional, online, learnable, fields, exercises] exercise determine least four adaptation steps one single rolf neuron four patterns stated presented one another indicated order let initial values rolf neuron furthermore let let 
[excursus, neural, networks, used, prediction] discussion application neural networks look ahead future time series discussing different paradigms neural networks useful take look application neural networks brought often see also used fraud application time series prediction excursus structured description time series estimations requirements actually needed predict values time series finally say something range software predict share prices economic characteristics means neural networks procedures chapter detailed description rather indicate approaches time series prediction respect try avoid formal definitions 
[excursus, neural, networks, used, prediction, time, series] time series series values discretized time example daily measured temperature values meteorological data specific site could represented time series share price values also represent time series often measurement time series timely equidistant many time series future development values interesting daily weather forecast time series also values actually continuous function read certain distance time fig figure function depends time sampled discrete time steps time dis cretized means result time series sampled values entered neural network example slp shall learn predict future values time series want predict time series look neural network maps previous series values future developments time series know longer sections time series enough training samples course examples future predicted tried generalize extrapolate past means said samples begin predict time series answer questions time series dealing ensure fulfills requirements evidence suggests future values depend way past values time series past time series include information future enough past values time series used training patterns case prediction continuous function must useful look like questions shall explored detail much information future included past values time series important question answered time series mapped future future values time series instance depend past values time series prediction based impossible chapter assume systems whose future values deduced states deterministic systems leads question system state system state completely describes system certain point time future deterministic system would clearly defined means complete description current state problem real world state concept includes things influence system means case weather forecast specific site could definitely determine tem perature atmospheric pressure cloud density meteorological state place time whole state would include significantly information worldwide phenomena control weather would interesting well small local pheonomena cooling system local power plant predictor figure representation one step ahead prediction tried calculate future value series past values predicting element case neural network referred predictor shall note system state desirable prediction always possible obtain often fragments current states acquired weather forecast fragments said weather data however partially overcome weaknesses using one single state last one prediction using several past states want derive first prediction system 
[excursus, neural, networks, used, prediction, one-step-ahead, prediction] first attempt predict next future value time series past values called one step ahead prediction fig predictor system receives last observed state parts system input outputs prediction next state state part idea state space predictable states called state space forecasting aim predictor realize function receives exactly past values order predict future value predicted values shall headed tilde distinguish actual future values intuitive simplest approach would find linear combination approximately fulfills conditions construction called digital filter use fact time series usually lot past values set series equations thus equations could found unknown coefficients solve possi ble another better approach could use equations unknowns way sum mean squared errors already known prediction minimized called moving average procedure linear structure corresponds singlelayer perceptron linear activation function trained means data past experimental setup would comply fig fact training means delta rule provides results close analytical solution even approach often provides satisfying results seen many prob lems cannot solved using singlelayer perceptron additional layers linear activation function useless well since multilayer perceptron linear activation functions reduced singlelayer perceptron considerations lead non linear approach multilayer perceptron non linear activation functions provide universal non linear function approximator use mlp inputs past rbf network could also used remember number remain low since rbf networks high input dimensions complex realize want include many past values multilayer perceptron require considerably less computational effort 
[excursus, neural, networks, used, prediction, two-step-ahead, prediction] approaches use see farther future without going detail want remark prediction becomes easier past values time series available would like ask reader read nyquist shannon sampling theorem predictor predictor figure representation two step ahead prediction attempt predict second future value past value series means second predictor involvement already predicted value 
[excursus, neural, networks, used, prediction, two-step-ahead, prediction, recursive, two-step-ahead, prediction] order extend prediction instance two time steps future could perform two one step ahead predictions row fig recursive two step ahead prediction unfortunately value determined means one step ahead prediction generally imprecise errors built predictions performed row imprecise becomes result 
[excursus, neural, networks, used, prediction, two-step-ahead, prediction, direct, two-step-ahead, prediction] already guessed exists better approach like system trained predict next value certainly train predict next one value means directly train example neural network look two time steps ahead future referred direct two step ahead prediction fig obviously direct two step ahead prediction technically identical one step ahead prediction difference training predictor figure representation direct two step ahead prediction second time step predicted directly first one omitted technically differ one step ahead prediction 
[excursus, neural, networks, used, prediction, additional, optimization, approaches, prediction] possibility predict values far away future important try look farther ahead future also periodic time series approaches hardly possible lecture begins every thursday useful know many people sat lecture room monday predict number lecture participants applies example periodically occurring commuter jams 
[excursus, neural, networks, used, prediction, additional, optimization, approaches, prediction, changing, temporal, parameters] thus useful intentionally leave gaps future values well past values time series introduce parameter indicates past value used prediction technically speaking still use one step ahead prediction extend input space train system predict values lying farther away also possible combine different case traffic jam prediction monday values last days could used data input addition values previous mondays thus use last values several periods case values weekly daily period could also include annual period form beginning holidays sure everyone already spent lot time highway forgot beginning holidays predictor figure representation heterogeneous one step ahead prediction prediction time series consideration second one predictor figure heterogeneous one step ahead prediction two time series time 
[excursus, neural, networks, used, prediction, additional, optimization, approaches, prediction, heterogeneous, prediction] another prediction approach would predict future values single time series several time series assumed additional time series related future first one heterogeneous one step ahead prediction fig want predict two outputs two related time series certainly possible perform two parallel one step ahead predictions analytically done often otherwise equations would become confusing case neural networks additional output neuron attached knowledge time series used outputs fig find general material time series 
[excursus, neural, networks, used, prediction, remarks, prediction, share, prices] many people observe changes share price past try conclude future values order benefit knowledge share prices discontinuous therefore principally difficult functions furthermore functions used discrete values often example daily rhythm including maximum minimum values per day lucky daily variations certainly eliminated makes whole thing even difficult chartists people look many diagrams decide means lot background knowledge decade long experience whether equities bought often successful apart share prices interesting predict exchange rates currencies exchange euros dollars dollars pounds pounds back euros could possible finally receive euros found would often thus would change exchange rates state increasing circulation would longer possible otherwise could produce money generating speak financial perpetual motion machine stock exchange successful stock currency brokers raise lower thumbs thereby indicate whether opinion share price exchange rate increase decrease mathematically speaking indicate first bit sign first derivative exchange rate way excellent worldclass brokers obtain success rates great britain heterogeneous one step ahead prediction successfully used increase accuracy predictions addition time series values indicators oil price rotterdam national debt included example show magnitude accuracy stock exchange evaluations since still talking first bit first derivation still know strong expected increase decrease also whether effort pay probably one wrong prediction could nullify profit one hundred correct predictions neural networks used predict share prices intuitively assume future share prices function previous share values assumption wrong share prices function past values function assumed future value buy shares values increased last days believe futher increase tomorrow consequence many people buy share boost price therefore assumption right self fulfilling prophecy generated phenomenon long known economics applies way around sell shares believe tomor row prices decrease beat prices next day generally even day next software appears uses scientific key words neural networks purport capable predict share prices going buy software addition aforementioned scientific exclusions one simple reason tools work manufacturer sell normally useful economic knowledge kept secret knew way definitely gain wealth means shares would earn millions using knowledge instead selling euros 
[excursus, reinforcement, learning] training samples would nevertheless possible evaluate well learned solve problem let examine learning paradigm situated supervised unsupervised learning want introduce exotic approach learning leave usual paths know learning procedures network exactly told provide exemplary output values also know learning procedures like self organizing maps input values entered want explore something learning paradigm reinforcement learning reinforcement learning according sutton barto reinforcement learning neural network one three learning paradigms already mentioned chapter sources counted among supervised learning procedures since feedback given due rudimentary feedback reasonable separate supervised learning procedures apart fact training samples generally known procedures backpropagation cannot work human brain reinforcement learning usually considered biologically motivated term reinforcement learning comes cognitive science psychology describes learning system carrot stick occurs everywhere nature learning means good bad experience reward punishment learning aid exactly explains receive total result process win game chess sure victory results individual intermediate steps example ride bike worn tires speed exactly turn sand grain size average nobody could tell exactly handlebar angle adjust even worse strong great number muscle parts arms legs contract depending whether reach end curve unharmed soon face learning experience feedback reward good bad thus reward simple hand considerably easier obtain tested different velocities turning angles often enough received rewards get feel works aim reinforcement learning maintain exactly feeling another example quasi impossibility achieve sort cost utility function tennis player tries maximize athletic success long term means complex movements ballistic trajectories three dimensional space including wind direction importance tournament private factors many get straight point since receive little feedback reinforcement learn ing often means trial error therefore slow 
[excursus, reinforcement, learning, system, structure] want briefly discuss different sizes components system define precisely following sections broadly speaking reinforcement learning represents mutual interaction agent environmental system fig agent shall solve problem could instance autonomous robot shall avoid obstacles agent performs actions within environment return receives feedback environment following called reward cycle action reward characteristic reinforcement learning agent influences system system provides reward changes reward real discrete scalar describes mentioned well achieve aim give guidance achieve aim always make sum rewards high possible long term 
[excursus, reinforcement, learning, system, structure, gridworld] learning example reinforcement learning would like use called gridworld see structure simple easy figure therefore reinforcement actually necessary however suitable representing approach reinforcement learning let exemplary define individual components reinforcement system means gridworld later components examined exactly environment gridworld fig simple discrete world two dimensions following want use environmental system agent agent use simple robot situated gridworld state space see gridworld fields fields unac cessible therefore agent occupy positions grid world positions regarded states agent action space actions still missing simply define robot could move one field right left long obstacle edge gridworld task agent task leave gridworld exit located right light colored field non determinism two obstacles connected door door closed lower part illustration corresponding field inaccessible position door cannot change cycle cycles created small world accompany following learning strategies illustrate 
[excursus, reinforcement, learning, system, structure, agent, und, environment] aim agent learns happens means reward thus trained means dynamic system environment order reach aim learning mean context agent shall learn mapping situations actions called policy shall learn situation achieve certain given aim aim simply shown agent giving award achievement figure graphical representation gridworld dark colored cells obstacles therefore inaccessible exit located right side light colored field symbol marks starting position agent upper part figure door open lower part closed agent action environment reward new situation figure agent performs actions within environment return receives reward award must mistaken reward agent way solution may sometimes useful receive smaller award punishment return longterm result maximum similar situation investor sits downturn share price pawn sacrifice chess game agent heading right direction towards target receives positive reward receives reward even negative reward punishment award speak final sum rewards also called return colloquially named basic components want discuss precisely components used make abstract reinforcement learning system gridworld gridworld agent simple robot find exit gridworld environment gridworld discrete gridworld definition agent reinforcement learning agent formally scribed mapping situation space action space mean ing situations defined later indicate action space depends current situation agent definition environment environment represents stochastic mapping action current situation reward new situation environment 
[excursus, reinforcement, learning, system, structure, states, situations, actions] already mentioned agent different states case gridworld example different positions get two dimensional state vector agent ist always possible realize information current state introduce term situation situation state agent point view less precise approximation state therefore situations generally allow clearly predict successor situations even completely deterministic system may applicable knew states transitions exactly thus complete system would possible plan optimally also easy find optimal policy methods provided example dynamic programming know reinforcement learning interaction agent system including actions situations agent cannot determine whether current situation good bad exactly reason receives said reward environment gridworld states positions agent situated simply said situations equal states gridworld possible actions would move towards north south east west situation action vectorial reward always scalar extreme case even binary value since aim reinforcement learning get along little feedback complex vectorial reward would equal real teaching input way cost function minimized would possible however vectorial reward since intuitive order relations multi dimensional space directly know better worse definition state within environment agent state states contain information agent within environmental system thus theoretically possible clearly predict successor state performed action within deterministic system godlike state knowledge definition situation situations time situation space agent limited approximate knowledge state approximation agent cannot even know good makes clear predictions impossible definition action actions performed agent whereupon could possible depending situation another action space exists cause state transitions therefore new situation agent point view 
[excursus, reinforcement, learning, system, structure, reward, return] real life aim receive award high possible maximize sum expected rewards called return long term finitely many time steps rewards simply added certainly return estimated knew rewards therefore return completely would longer necessary learn definition reward reward scalar real discrete even sometimes binary reward punishment environmental system returns agent reaction action definition return return accumulation received rewards time dealing long periods time however every problem explicit target therefore finite sum agent robot task drive around avoid obstacles order receive diverging sum case infinite series reward estimations weakening factor used weakens influence future rewards useful exists target also target far away farther reward away smaller influence agent deci sions practice finitely many time steps possible even though formulas stated infinite sum first place another possibility handle return sum would limited time horizon many following rewards regarded thus divide timeline episodes usually one two methods used limit sum methods together daily living try approximate current situation desired state since mandatory next expected reward expected total sum decides agent also possible perform actions short notice result negative reward pawn sacrifice chess game pay later 
[excursus, reinforcement, learning, system, structure, policy] considered formalized system components reinforcement learning actual aim still discussed reinforcement learning agent learns policy thus continuously adjusts mapping situations probabilities action performed situation policy defined strategy select actions would maximize reward long term gridworld gridworld policy strategy according agent tries exit gridworld definition policy policy mapping situations probabilities perform every action action space formalized basically distinguish two policy paradigms open loop policy rep resents open control chain creates initial situation sequence actions thus beginning agent develops plan consecutively executes end without considering intermediate situations therefore actions depend situations gridworld gridworld open loop policy would provide precise direc tion towards exit way given starting position abbrevi ations directions eeeen open loop policy sequence actions without interim feedback sequence actions generated starting situation system known well truly open loop policy used successfully lead useful results example know chess game well truly would necessary try every possible move would time consuming thus problems find alternative open loop policy incorporates current situations action plan closed loop policy closed loop function manner speaking environment influences action agent responds input environment respectively already illustrated fig closed loop policy speak reactive plan map current situations actions performed gridworld closed loop policy would responsive current position choose direction according action particular obstacle appears dynamically policy better choice selecting actions performed two basic strategies exam ined exploitation exploration real life reinforcement learning often question arises whether exisiting knowledge willfully exploited new ways also explored initially want discuss two extremes greedy policy always chooses way highest reward deter mined advance way highest known reward policy represents exploitation approach promising used system already known contrast exploitation approach aim exploration approach explore system detailed possible also paths leading target found may promising first glance fact successful let assume looking way restaurant safe policy would always take way already know matter unoptimal long may try explore better ways another approach would explore shorter ways every even risk taking long time unsuccessful therefore finally take original way arrive late restaurant reality often combination methods applied beginning learning process researched higher probability end existing knowledge exploited static probability distribution also possible often applied gridworld finding way gridworld restaurant example applies equally 
[excursus, reinforcement, learning, learning, process] let take look daily life actions lead one situation different subsituations subsituation sub subsituations sense get situation tree links nodes must considered often several ways reach situation tree could accurately referred situation graph leaves tree end situations system exploration approach would search tree thoroughly possible become acquainted leaves exploitation approach would unerringly best known leave analogous situation tree also create action tree rewards actions within nodes adapt daily life learn exactly 
[excursus, reinforcement, learning, learning, process, rewarding, strategies] interesting important question reward kind reward awarded since design reward significantly controls system behavior seen generally daily life various actions performed situation different strategies evaluate selected situations learn series actions would lead target first principle explained following want indicate extreme cases design examples reward rewarding similar rewarding chess game referred pure delayed reward receive reward end game method always advantageous finally say whether succesful interim steps allow estimation situation win well lose rewarding strategy reward returned leaves situation tree pure negative reward system finds rapid way reach target way automat ically favorable one respect reward agent receives punishment anything even nothing result inexpensive method agent reach target fast another strategy avoidance strategy harmful situations avoided situations receive reward receive negative reward agent agent avoid getting close negative situations warning rewarding strategies unexpected consequences robot told way touch obstacle punished simply stand still standing still also punished drive small circles reconsidering understand behavior optimally fulfills return robot unfortunately intended furthermore show especially small tasks solved better means negative rewards positive differentiated rewards useful large complex tasks gridworld want apply pure negative reward strategy robot shall find exit fast possible figure representation optimal return per field gridworld means pure negative reward awarding top open bottom closed door 
[excursus, reinforcement, learning, learning, process, state-value, function] unlike agent godlike view gridworld swiftly determine robot starting position provide optimal return figure optimal returns applied per field gridworld state value function gridworld exactly represents function per situation position difference function unknown learned thus see would practical robot capable evaluate current future situations let take look another system component reinforcement learning state value function regard policy often called whether situation bad often depends general behavior agent situation bad policy searching risks checking limits would instance agent bicycle turns corner front wheel begins slide due daredevil policy agent would brake situation risk aware policy situations would look much better thus would evaluated higher good state value function simply returns value current situation agent policy abstractly speaking according definitions value state value function corresponds return expected value situation denotes set expected returns current situation definition state value function state value function task determining value situations policy answer agent question whether situation good bad good bad purpose returns expectation return situation optimal state value function called unfortunaely unlike robot godlike view environment table optimal returns like one shown orient aim reinforcement learning robot generates state value function bit bit basis returns many trials approximates optimal state value function one context want introduce two terms closely related cycle state value function policy policy evaluation policy evaluation approach try policy times provide many rewards way gradually accumulate state value function means rewards policy improvement policy improvement means improve policy turn new better one order improve policy aim return finally larger value found shorter way restaurant walked successfully figure cycle reinforcement learning ideally leads optimal principle reinforcement learning realize interaction tried evaluate good policy individual situations changed state value function provides information system improve policy two values lift mathematically proved final result optimal policy optimal state value function fig cycle sounds simple time consuming first let regard simple random policy robot could slowly fulfill improve state value function without previous knowledge 
[excursus, reinforcement, learning, learning, process, monte, carlo, method] easiest approach accumulate state value function mere trial error thus select randomly behaving policy consider accumulated state value function random decisions proved point find exit gridworld chance inspired random based games chance approach called monte carlo method additionally assume pure negative reward obvious receive optimum value starting field state value function depending random way random policy takes values smaller occur starting field intuitively want memorize better value one state one field caution advised way learning procedure would work deterministic systems door open closed cycle would produce oscillations fields oscillations would influence shortest way target monte carlo method prefer use learning rule new alt alt update state value function obviously influenced old state value received return learning rate thus agent gets kind memory new findings always change situation value little bit exemplary learning step shown fig example computation state value applied one single state initial state obvious possible often done train values states visited case gridworld ways target time result calculation related example illustrated fig monte carlo method seems suboptimal usually significantly slower following methods reinforcement learning method one mathematically proved works therefore useful theoretical considerations definition monte carlo learning actions randomly performed regardless state value function long term expressive state value function accumulated means following learning rule new alt alt 
[excursus, reinforcement, learning, learning, process, temporal, difference, learning] learning result experiences walking riding bicycle without getting injured even mental skills like mathematical problem solving benefit lot experience simple trial error thus initialize policy arbitrary values try learn improve policy due experience fig contrast monte carlo method want directed manner learn experience react different situations different ways temporal difference learning abbreviated learning training agent learns estimate situations worth lot current situation identified following situations learning rule among others derived means bellman equation derivation discussed chapter figure application monte carlo learning rule learning rate top two exemplary ways agent randomly selects applied one open one closed door bottom result learning rule value initial state considering ways due fact course time many different ways walked given random policy expressive state value function obtained figure extension learning example fig returns intermediate states also used accumulate state value function low value door field seen well state possible must positive door closed state impossible evaluation policy improvement figure try different actions within environment result learn improve policy thus learning formula state value function new change previous value see change value current situation proportional learning rate influenced received reward previous return weighted factor following situation previous value situation definition temporal difference learning unlike monte carlo method learning looks ahead regarding following situation thus learning rule given new change previous value 
[excursus, reinforcement, learning, learning, process, action-value, function] analogous state value function action value function another system component reinforcement learning evaluates certain action certain situation policy gridworld gridworld action value function tells good move certain field certain direction fig definition action value function like state value function action value function evaluates certain actions basis certain situations policy optimal action value function called shown fig actions performed target situation referred achieved exists target situation otherwise actions simply performed figure exemplary values action value function position moving right one remains fastest way towards target moving still quite fast way moving good way provided door open cases gfed abc direction actions gfed abc gfed abc onml hijk gfed abc direction reward figure actions performed desired target situation achieved attention paid numbering rewards numbered beginning actions situations beginning simply adopted convention 
[excursus, reinforcement, learning, learning, process, learning] implies learning fomula action value function analo gously learning application called learning new max greedy strategy change previous value break change current action value proportional learning rate current situation influenced received reward maximum action following actions weighted greedy strategy applied since assumed best known action selected learning hand mind always get best known next situation previous value action situation known remem ber also weighted means usually action value function learns considerably faster state value func tion must disregard reinforcement learning generally quite slow system find good advantage learning initialized arbitrarily means learning result always definition learning learning trains action value function means learning rule new max thus finds case 
[excursus, reinforcement, learning, example, applications, gammon] gammon successful backgammon game based learning invented gerald tesauro situation current configuration board anyone ever played backgammon knows situation space huge approx situations result state value functions cannot computed explicitly particularly late eighties gammon introduced selected rewarding strategy pure delayed reward system receives reward end game time reward return system allowed practice initially backgammon program entity result achieved highest ranking computer backgammon league strikingly disproved theory computer programm capable master task better programmer 
[excursus, reinforcement, learning, example, applications, car, pit] let take look car parking one dimensional road bottom deep pit without able get slope sides straight away means engine power order leave pit trivially executable actions possibilities drive forwards backwards intuitive solution think immediately move backwards gain momentum opposite slope oscillate way several times dash pit actions reinforcement learning system would full throttle forward full reverse nothing everything costs would good choice awarding reward system learns fast leave pit realizes problem cannot solved means mere forward directed engine power system slowly build movement policy longer stored table since state space hard discretize policy function generated 
[excursus, reinforcement, learning, example, applications, pole, balancer] pole balancer developed barto sutton anderson let given situation including vehicle capable move either right full throttle left full throttle bang bang control two actions performed standing still impossible top car hinged upright pole could tip sides pole built way always tips one side never stands still let assume pole rounded lower end angle pole relative vertical line referred furthermore vehicle always fixed position one dimensional world velocity one dimensional world limited maximum values minimum values adopt aim system learn steer car way balance pole prevent pole tipping achieved best avoidance strategy long pole balanced reward pole tips reward interestingly system soon capable keep pole balanced tilting suffi ciently fast small movements system mostly center space since farthest walls understands negative touches wall pole tip swinging inverted pendulum difficult system following initial situation pole initially hangs swung vehicle finally stabilized literature task called swing inverted pendulum 
[excursus, reinforcement, learning, reinforcement, learning, connection, neural, networks] finally reader would like ask text neural networks includes chapter reinforcement learning answer simple already introduced supervised unsu pervised learning procedures although always omniscient teacher makes unsupervised learning possible mean receive feedback often something kind criticism school mark problems like solved means reinforcement learning every problem easily solved like gridworld backgammon example approx situations situation tree large branching factor let alone games tables used gridworld longer realized state action value functions thus find approximators functions learning approximators reinforcement learning components come immediately mind exactly neural networks 
[excursus, reinforcement, learning, exercises] exercise robot control system shall persuaded means reinforcement learning find strategy order exit maze fast possible could appropriate state value function look like would generate appropriate reward assume robot capable avoid obstacles time knows position orientation exercise describe function two components ase ace proposed barto sutton anderson control pole balancer bibliography exercise indicate several classical problems informatics could solved efficiently means reinforcement learning please give reasons answers 
